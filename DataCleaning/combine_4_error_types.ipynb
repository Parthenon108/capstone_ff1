{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from functools import reduce\n",
    "import pytz\n",
    "import altair as alt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# These are the datasets uploaded by Jacob to blob storage:\n",
    "df_app = pd.read_parquet('../do_not_commit/Datasets/AppErrorEvents.parquet')\n",
    "df_win = pd.read_parquet('../do_not_commit/Datasets/WindowsErrorEvents.parquet')\n",
    "df_hang = pd.read_parquet('../do_not_commit/Datasets/AppHangEvents.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(len(df_app))\n",
    "print(len(df_win))\n",
    "print(len(df_hang))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_app['error_type'] = \"Application\"\n",
    "df_win['error_type'] = 'Windows'\n",
    "df_hang['error_type'] = 'Hang'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_compare_chart(in_data, in_col, in_title):\n",
    "    \"\"\"\n",
    "    # Visualize codes by EventName in df_win['EventName'].\n",
    "\n",
    "    :param in_data:\n",
    "    :param in_col:\n",
    "    :param in_title:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    count_df2 = in_data.groupby(in_col).size().reset_index().rename(columns={0: 'count'})\n",
    "    # Sort order for chart\n",
    "    count_df2.sort_values('count', ascending=False, inplace=True)\n",
    "    sort_order = [val for val in count_df2[in_col].unique()]\n",
    "    out_chart = alt.Chart(count_df2).mark_bar().encode(\n",
    "        x=alt.X('count:Q'),\n",
    "        y=alt.Y(in_col + ':N', sort=sort_order),\n",
    "        tooltip='count:Q'\n",
    "    ).properties(title=in_title)\n",
    "    return out_chart\n",
    "\n",
    "\n",
    "def show_bar_for_win_event(eventname_list, in_df, visualize_attr):\n",
    "    for eventname in eventname_list:\n",
    "        current_df = in_df[in_df['EventName'] == eventname]\n",
    "        out_chart = get_compare_chart(current_df, visualize_attr,\n",
    "                                      f'Counts of {visualize_attr} types for {eventname} events')\n",
    "        yield out_chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get the event names\n",
    "eventnames = df_win['EventName'].unique()\n",
    "charts = show_bar_for_win_event(eventnames, df_win, 'ProblemSignatureP3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Uncomment below to cycle through charts:\n",
    "# current_chart = next(charts)\n",
    "# current_chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(df_win['ProblemSignatureP3'].str.contains('.dll').sum())\n",
    "print(len(df_win))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# COALESCE() in order: https://www.statology.org/pandas-coalesce/\n",
    "df_win['Combined_dll'] = df_win[['ProblemSignatureP3', 'ProblemSignatureP6']].bfill(axis=1).iloc[:, 0]\n",
    "df_win['Combined_dll'] = df_win['Combined_dll'].apply(lambda x: x if '.dll' in str(x) else np.nan)\n",
    "df_win.drop(columns=['ProblemSignatureP3', 'ProblemSignatureP6'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_app.rename(\n",
    "    columns={\n",
    "        'FaultingApplicationName':'Combined_Application',\n",
    "        'ProgramId':'ProgramID',\n",
    "        'FileId':'FileID',\n",
    "        'AppVersion':'Combined_Version',\n",
    "        'ExceptionCode':'Combined_Exception',\n",
    "        'FaultingProcessId':'Combined_ProcessID',\n",
    "        'ReportId':'Combined_ReportID',\n",
    "        'FaultingApplicationStartTime':'Combined_StartTime',\n",
    "        'FaultingModuleName':'Combined_dll'\n",
    "    },\n",
    "    inplace=True\n",
    ")\n",
    "\n",
    "df_win.rename(\n",
    "    columns={\n",
    "        'ProblemSignatureP1_Application':'Combined_Application',\n",
    "        'ProblemSignatureP2_AppVersion':'Combined_Version',\n",
    "        'ProblemSignatureP7_ExceptionCode':'Combined_Exception',\n",
    "        'ReportID':'Combined_ReportID',\n",
    "        'CabGuid':'CabGUID'\n",
    "    },\n",
    "    inplace=True\n",
    ")\n",
    "\n",
    "df_hang.rename(\n",
    "    columns={\n",
    "        'ProgramId':'ProgramID',\n",
    "        'FileId':'FileID',\n",
    "        'Program':'Combined_Application',\n",
    "        'ProgramVersion':'Combined_Version',\n",
    "        'ProcessID':'Combined_ProcessID',\n",
    "        'ReportID':'Combined_ReportID',\n",
    "        'StartTime':'Combined_StartTime'\n",
    "    },\n",
    "    inplace=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "events = pd.concat([df_app, df_win, df_hang])\n",
    "events.reset_index(inplace=True)\n",
    "events.dropna(axis=1, how='all', inplace=True) # Dropping columns with nothing in them.\n",
    "# msno.matrix(events.iloc[:, 20:], labels=True, fontsize=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(events)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "\n",
    "<a id=\"machines_events\"></a>\n",
    "# Join events with machines.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "machines = pd.read_parquet('../do_not_commit/Datasets/Persist_System_DISC.pq')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "machines['ClientItemKey'] = machines['ItemKey'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Join machine name ('Name0') to events by internal date and ClientItemKey (a different, but similar ID for a machine).\n",
    "# Because events is left, every row will have a TimeCreatedSystemTime.\n",
    "machines_events = events.merge(machines[['RWB_EFFECTIVE_DATE', 'ClientItemKey', 'Name0']], on=['RWB_EFFECTIVE_DATE', 'ClientItemKey'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Convert the TimeCreatedSystemTime CST column from Datetime to a date datatype (formatted like YYYY-MM-DD).\n",
    "machines_events['TimeCreatedSystemTimeFormatted'] = machines_events['TimeCreatedSystemTime'].dt.strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Convert local time values to Central.\n",
    "def convert_to_cst(df:pd.DataFrame, utc_column_name:str, cst_column_name:str):\n",
    "    \"\"\"\n",
    "    Create a new column in the events dataframe that converts the TimeCreatedSystemTime from UTC to CST.\n",
    "    (this is necessary because RWB_EFFECTIVE_DATE is in CST)\n",
    "    \"\"\"\n",
    "\n",
    "    # Make sure the UTC column is in datetime format\n",
    "    df[utc_column_name] = pd.to_datetime(df[utc_column_name])\n",
    "\n",
    "    # Convert to UTC timezone\n",
    "    utc_timezone = pytz.timezone('UTC')\n",
    "    df[utc_column_name] = df[utc_column_name].dt.tz_localize(utc_timezone)\n",
    "\n",
    "    # Convert to Central Standard Time (CST) timezone\n",
    "    cst_timezone = pytz.timezone('America/Chicago')\n",
    "    df[cst_column_name] = df[utc_column_name].dt.tz_convert(cst_timezone)\n",
    "\n",
    "    # Drop the original UTC column if desired (optional)\n",
    "    # df.drop(columns=[utc_column_name], inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "machines_events = convert_to_cst(machines_events, utc_column_name='TimeCreatedSystemTime', cst_column_name='CreatedSystemTime_CST')\n",
    "machines_events[['TimeCreatedSystemTime', 'CreatedSystemTime_CST']].sample(5) # Check all times are -05:00 or -06:00 from UTC (Daylight Savings Time)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Convert the TimeCreatedSystemTime CST column from Datetime to a date datatype (formatted like YYYY-MM-DD).\n",
    "machines_events['CreatedSystemTime_CST_formatted'] = machines_events['CreatedSystemTime_CST'].dt.strftime('%Y-%m-%d')\n",
    "machines_events['CreatedSystemTime_CST_formatted'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "type(pd.to_datetime('2023-07-23 00:01:00').date())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "\n",
    "# Join Boot events with machines separately.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_boot = pd.read_parquet('../do_not_commit/Datasets/BootEvents.parquet')\n",
    "print(len(df_boot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_boot['error_type'] = 'Boot'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# What columns do all four event types have in common?\n",
    "common_columns = reduce(np.intersect1d, (df_app.columns, df_boot.columns, df_hang.columns, df_win.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_boot.rename(\n",
    "    columns={\n",
    "        'BootId':'BootID',\n",
    "        'ProgramId':'ProgramID',\n",
    "        'FileId':'FileID',\n",
    "        'AppVersion':'Combined_Version',\n",
    "        'ExceptionCode':'Combined_Exception',\n",
    "        'ReportId':'ReportID'\n",
    "    },\n",
    "    inplace=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Needs to be a str to join later w/ 'opened_at_formatted'.\n",
    "# BootID is synonymous with 'TimeCreatedSystemTime'\n",
    "# since it is the time on the machine when the boot event occurred.\n",
    "df_boot['BootID_formatted'] = df_boot['BootID'].dt.strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Join machine name to boot events, similar to other section.\n",
    "machines_boot = df_boot.merge(machines[['RWB_EFFECTIVE_DATE', 'ClientItemKey', 'Name0']], on=['RWB_EFFECTIVE_DATE', 'ClientItemKey'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "\n",
    "# Join machines and events with INCs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# From blob storage:\n",
    "# incs = pd.read_csv('../do_not_commit/Datasets/ServiceNow_Incident.csv', low_memory=False)\n",
    "incs = pd.read_csv('../do_not_commit/Datasets/ServiceNow_INC_20230730.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# DateTime formatting.\n",
    "incs['opened_at'] = pd.to_datetime(incs['opened_at'])\n",
    "incs['opened_at_formatted'] = incs['opened_at'].dt.strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Join INCs to events on:\n",
    "# 1. Machine name, and\n",
    "# 2. The event and the INC both occurred on the same day, using %Y-%m-%d format (YYYY-MM-DD).\n",
    "incs_merged = machines_events.merge(incs, left_on=['Name0', 'CreatedSystemTime_CST_formatted'], right_on=['configuration_item', 'opened_at_formatted'], how='left')\n",
    "print(len(incs_merged))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Drop columns with nothing in them.\n",
    "incs_merged.dropna(axis=1, how='all', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Should be many more. Why only still 4,000?\n",
    "print(len(incs), \"INC rows originally\")\n",
    "print(\"Now\", incs_merged['number'].notnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "\n",
    "#### Remove INCs assc. w/ events *after* the INC was already filed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "incs_merged['opened_at_cst_not_utc'] = incs_merged['opened_at'].dt.tz_localize('US/Central')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"CreatedSystemTime_CST:\", incs_merged.loc[74, 'CreatedSystemTime_CST'])\n",
    "print(\"INC file time CST:    \", incs_merged.loc[74, 'opened_at_cst_not_utc'])\n",
    "print(\"CreatedCST-opened_at: \", incs_merged.loc[74, 'CreatedSystemTime_CST'] - incs_merged.loc[74, 'opened_at_cst_not_utc'])\n",
    "# This event happened before the INC was filed, at 13:28 UTC vs 16:20 UTC (2h 52m):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"CreatedSystemTime_CST:\", incs_merged.loc[75, 'CreatedSystemTime_CST'])\n",
    "print(\"INC file time CST:    \", incs_merged.loc[75, 'opened_at_cst_not_utc'])\n",
    "print(\"CreatedCST-opened_at: \", incs_merged.loc[75, 'CreatedSystemTime_CST'] - incs_merged.loc[74, 'opened_at_cst_not_utc'])\n",
    "# This event happened after the INC was filed, at 20:23 UTC vs 16:20 UTC (4h 3m):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Delete INCs across rows when the event occurs before the INC on the same day.\n",
    "mask = incs_merged['CreatedSystemTime_CST'] >= incs_merged['opened_at_cst_not_utc']\n",
    "columns_to_set_none = incs.columns\n",
    "incs_merged.loc[mask, columns_to_set_none] = None\n",
    "\n",
    "# Looks like no 'CreatedSystemTime_CST value is > 'opened_at'.\n",
    "incs_merged[incs_merged['number'].notnull()][['CreatedSystemTime_CST', 'opened_at', 'number']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Check to make sure. Positive = delete. Negative = keep.\n",
    "(incs_merged['CreatedSystemTime_CST'] - incs_merged['opened_at_cst_not_utc']).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Timedelta of -1 days (24h) + 16:04 = 8h 04m difference in true time.\n",
    "incs_merged.loc[502, ['CreatedSystemTime_CST', 'opened_at_cst_not_utc']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "\n",
    "# Join machines and boot events with INCs separately.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "incs_boot = machines_boot.merge(incs, left_on=['Name0', 'BootID_formatted'], right_on=['configuration_item', 'opened_at_formatted'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(incs_boot['number'].notnull().sum(), \"Boot INCs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Dropping columns with nothing in them.\n",
    "incs_boot.dropna(axis=1, how='all', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# How many multiple INCs were filed on the same day for a given machine?\n",
    "grouped_counts = incs.groupby(['opened_at_formatted', 'configuration_item']).size()\n",
    "print(grouped_counts[grouped_counts > 1].sum())\n",
    "grouped_counts[grouped_counts > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "incs_boot[incs_boot['number'].notnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "\n",
    "# Bring machines, events, and INCs together for both regular events and Boot events.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.concat([incs_merged, incs_boot])\n",
    "df.reset_index(inplace=True)\n",
    "\n",
    "# Dropping columns with nothing in them.\n",
    "df.dropna(axis=1, how='all', inplace=True)\n",
    "\n",
    "# Drop all data for May 20th, 2023.\n",
    "df = df[df['RWB_EFFECTIVE_DATE'] != '2023-05-20']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(df[df['error_type'].isin(['Application', 'Hang', 'Windows'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(df[df['error_type'] != 'Boot'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['error_type'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(df.shape)\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# How many boot events occurred after an INC was filed?\n",
    "# df[df['error_type'] == 'Boot']['BootID'] - df[df['error_type'] == 'Boot']['opened_at_cst_not_utc']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "\n",
    "# Create 'num_events' feature.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'CreatedSystemTime_CST_formatted' in list(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Because 'TimeCreatedSystemTime' never exists in 'df_boot',\n",
    "# 'CreatedSystemTime_CST_formatted' will always be pd.NaT for Boot events,\n",
    "# because it is unique to the regular events only.\n",
    "df[df['error_type'] == 'Boot']['CreatedSystemTime_CST'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create the events feature by grouping by ClientItemKey and the TimeCreatedSystemTime CST date column,\n",
    "# and get the count of events for each machine each day.\n",
    "# Boot events excluded by default on basis of the .groupby() columns.\n",
    "\n",
    "# num_events = df.groupby(['RWB_EFFECTIVE_DATE', 'ClientItemKey']).agg('size').reset_index().rename(columns={0:'events'})\n",
    "num_events = df[df['error_type'] != 'Boot'].groupby(['ClientItemKey', 'CreatedSystemTime_CST_formatted']).agg('size').reset_index().rename(columns={0:'events'})\n",
    "num_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_events['events'].hist(bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "check_this_df = pd.read_parquet('../do_not_commit/FeatureDatasets/num_events.pq')\n",
    "print(check_this_df['events'].sum())\n",
    "check_this_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Export the result to parquet and save to blob storage.\n",
    "num_events.to_parquet('../do_not_commit/FeatureDatasets/num_events.pq')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "\n",
    "# Create 'num_events_incs' feature.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 'opened_at_formatted' was wiped for all events (rows) after an INC was filed on same day\n",
    "# in the join machines + events + incs section. If no value exists for any events\n",
    "# after an INC was filed, subsetting with .notnull() should give us what we need.\n",
    "\n",
    "num_events_inc = df[\n",
    "    (df['error_type'] != 'Boot') &\n",
    "    (df['opened_at_formatted'].notnull())\n",
    "].groupby(['ClientItemKey', 'CreatedSystemTime_CST_formatted']).agg('size').reset_index().rename(columns={0:'events'})\n",
    "num_events_inc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 'CreatedSystemTime_CST' is in CST, 'opened_at' is in UTC, a difference of 6 hours.\n",
    "df[(df['ClientItemKey'] == 16790461) & (df['CreatedSystemTime_CST_formatted'] == '2023-02-22')][['CreatedSystemTime_CST', 'opened_at']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_events_inc['events'].hist(bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "check_this_df = pd.read_parquet('../do_not_commit/FeatureDatasets/num_events_inc.pq')\n",
    "print(check_this_df['events'].sum())\n",
    "check_this_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Export the result to parquet and save to blob storage.\n",
    "num_events_inc.to_parquet('../do_not_commit/FeatureDatasets/num_events_inc.pq')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "\n",
    "#### How many INCs contain direct reference to BSOD?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['short_description_NER'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# How many short descriptions talk about BSODs?\n",
    "len(df.dropna(subset='short_description_NER')[df.dropna(subset='short_description_NER')['short_description_NER'].str.contains(\"(?i)Blue Screen|BSOD|[Dd]eath\")]['number'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# What is the frequency of each error type for BSOD tickets?\n",
    "df.dropna(subset='short_description_NER')[df.dropna(subset='short_description_NER')['short_description_NER'].str.contains(\"(?i)Blue Screen|BSOD|[Dd]eath\")].drop_duplicates('number', keep='first')['error_type'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.dropna(subset='short_description_NER')[(df.dropna(subset='short_description_NER')['short_description_NER'].str.contains(\"(?i)Blue Screen|BSOD|[Dd]eath\"))].drop_duplicates('number', keep='first')[['error_type', 'Combined_Application', 'Combined_dll', 'Combined_Exception']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.dropna(subset='short_description_NER')[(df.dropna(subset='short_description_NER')['short_description_NER'].str.contains(\"(?i)Blue Screen|BSOD|[Dd]eath\")) & (df['error_type'] == 'Application')].drop_duplicates('number', keep='first')['Combined_Application']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.dropna(subset='short_description_NER')[(df.dropna(subset='short_description_NER')['short_description_NER'].str.contains(\"(?i)Blue Screen|BSOD|[Dd]eath\")) & (df['error_type'] == 'Boot')].drop_duplicates('number', keep='first')['short_description_NER']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "\n",
    "#### What is the distribution of FaultApplicationName among INCs?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_check = df[df['error_type'] == 'Application']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_check['Combined_Application'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "\n",
    "#### What is the distribution of modules among INCs?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_check['Combined_dll'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "\n",
    "#### Which exception codes are most common among INCs?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_check[['Combined_Application', 'Combined_Exception']].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Incident category and faulting applications figure for report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = incs_merged\n",
    "if isinstance(df, (pd.DatetimeIndex, pd.MultiIndex)):\n",
    "\tdf = df.to_frame(index=False)\n",
    "\n",
    "\n",
    "df = df.query(\"\"\"`number`.str.contains('INC', na=False, case=False, regex=False)\"\"\")\n",
    "\n",
    "s2 = df[~pd.isnull(df['Combined_Application'])]\n",
    "\n",
    "def get_compare_chart(in_data, in_col, x_axis_title, y_axis_title, in_title):\n",
    "    \"\"\"\n",
    "    Visualize the top n most common faulting applications \n",
    "    \"\"\"\n",
    "\n",
    "    count_df2 = in_data.groupby(in_col).size().reset_index().rename(columns={0: 'count'})\n",
    "    # Sort order for chart\n",
    "    count_df2.sort_values('count', ascending=False, inplace=True)\n",
    "    count_df2 = count_df2.iloc[:10]\n",
    "    sort_order = [val for val in count_df2[in_col].unique()]\n",
    "    out_chart = alt.Chart(count_df2).mark_bar().encode(\n",
    "        x=alt.X('count:Q', axis=alt.Axis(title=x_axis_title)),\n",
    "        y=alt.Y(in_col + ':N',axis=alt.Axis(title=y_axis_title), sort=sort_order),\n",
    "        tooltip='count:Q'\n",
    "    ).properties(title=in_title)\n",
    "    return out_chart\n",
    "\n",
    "get_compare_chart(s2, 'Combined_Application', 'No. of Events', 'Faulting Application Name', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### CATEGORY AND SUBCATEGORY Visuals ### \n",
    "\n",
    "def get_compare_chart(in_data, in_col, x_axis_title, y_axis_title, in_title):\n",
    "    \"\"\"\n",
    "    Visualize the top n most common faulting applications \n",
    "    \"\"\"\n",
    "\n",
    "    count_df2 = in_data.groupby(in_col).size().reset_index().rename(columns={0: 'count'})\n",
    "    # Sort order for chart\n",
    "    count_df2.sort_values('count', ascending=False, inplace=True)\n",
    "    count_df2 = count_df2.iloc[:10]\n",
    "    sort_order = [val for val in count_df2[in_col].unique()]\n",
    "    axis_config = alt.AxisConfig(titleFontSize=15, labelFontSize=11) \n",
    "    out_chart = alt.Chart(count_df2).mark_bar().encode(\n",
    "        x=alt.X('count:Q', axis=alt.Axis(title=x_axis_title, \n",
    "                                         titleFontSize=axis_config.titleFontSize,\n",
    "                                           labelFontSize=axis_config.labelFontSize)),\n",
    "        y=alt.Y(in_col + ':N',axis=alt.Axis(title=y_axis_title, \n",
    "                                            titleFontSize=axis_config.titleFontSize, \n",
    "                                            labelFontSize=axis_config.labelFontSize),\n",
    "                                              sort=sort_order),\n",
    "        tooltip='count:Q'\n",
    "    ).properties(title=in_title)\n",
    "    return out_chart\n",
    "\n",
    "\n",
    "out = get_compare_chart(s, 'category', 'No. of Incidents', 'Incident Category', '') | get_compare_chart(s, 'subcategory',  'No. Incidents', 'Incident Subcategory', '') \n",
    "\n",
    "out"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
