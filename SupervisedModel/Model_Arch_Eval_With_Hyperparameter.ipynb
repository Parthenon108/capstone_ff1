{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-14T15:09:45.029965490Z",
     "start_time": "2023-08-14T15:09:44.909429295Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Pre-processing.\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Dummy.\n",
    "from sklearn.dummy import DummyRegressor\n",
    "\n",
    "# Models.\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge, ElasticNet\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "\n",
    "# Metrics.\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "# Evaluating.\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "# Step 1: Load data\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-14T15:09:45.155658374Z",
     "start_time": "2023-08-14T15:09:44.919424313Z"
    }
   },
   "outputs": [],
   "source": [
    "training_data = pd.read_parquet('./assets/training_set_v2.parquet')\n",
    "test_data = pd.read_parquet('./assets/test_set_v2.parquet')\n",
    "validation_data = pd.read_parquet('./assets/validation_set_v2.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "# Step 2: Standardize data\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "# Make sure y isn't in X.\n",
    "columns_to_drop = ['events', 'ItemKey', 'RWB_EFFECTIVE_DATE']\n",
    "X_train = training_data.drop(columns=columns_to_drop, axis=1)\n",
    "X_test = test_data.drop(columns=columns_to_drop, axis=1)\n",
    "X_val = validation_data.drop(columns=columns_to_drop, axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-14T15:09:45.255970765Z",
     "start_time": "2023-08-14T15:09:44.990324063Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "# Standardize values within each column to have a mean=0 and std=1.\n",
    "scaler = StandardScaler()\n",
    "X_train_std = scaler.fit_transform(X_train)\n",
    "X_test_std = scaler.transform(X_test)\n",
    "X_val_std = scaler.transform(X_val)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-14T15:09:45.597258391Z",
     "start_time": "2023-08-14T15:09:44.997412786Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "# Do not standardize y.\n",
    "y_train = training_data['events']\n",
    "y_test = test_data['events']\n",
    "y_val = validation_data['events']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-14T15:09:45.643314719Z",
     "start_time": "2023-08-14T15:09:45.599421238Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "# Step 3: Instantiate dummy regressors\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "dummy_regressor_mean = DummyRegressor(strategy='mean')\n",
    "dummy_regressor_median = DummyRegressor(strategy='median')\n",
    "dummy_regressor_quantile = DummyRegressor(strategy='quantile', quantile=0.25)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-14T15:09:45.645525011Z",
     "start_time": "2023-08-14T15:09:45.643628606Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "# Step 4: Define models\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "models = {\n",
    "    'Dummy Mean': dummy_regressor_mean,\n",
    "    'Dummy Median': dummy_regressor_median,\n",
    "    'Dummy Quantile': dummy_regressor_quantile,\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Lasso Regression': Lasso(),\n",
    "    'Ridge Regression': Ridge(),\n",
    "    'Elastic Net Regression': ElasticNet(),\n",
    "    'Decision Tree Regression': DecisionTreeRegressor(),\n",
    "    'Random Forest Regression': RandomForestRegressor(),\n",
    "    'Gradient Boosting Regression': GradientBoostingRegressor()\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-14T15:09:45.645753972Z",
     "start_time": "2023-08-14T15:09:45.643848846Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "# Step 5: Evaluate each model\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "val_results = []\n",
    "for model_name, model in models.items():\n",
    "    model.fit(X_train_std, y_train)\n",
    "    predictions_val = model.predict(X_val_std)\n",
    "\n",
    "    mse_val = mean_squared_error(y_val, predictions_val)\n",
    "    rmse_test = np.sqrt(mse_val)\n",
    "    mae_val = mean_absolute_error(y_val, predictions_val)\n",
    "\n",
    "    val_results.append([model_name, mse_val, rmse_test, mae_val])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-14T15:12:05.753542382Z",
     "start_time": "2023-08-14T15:09:45.644013841Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "# Step 6: Load results into a DataFrame\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "data": {
      "text/plain": "<pandas.io.formats.style.Styler at 0x7f65cd51a590>",
      "text/html": "<style type=\"text/css\">\n#T_ce07c_row1_col2, #T_ce07c_row2_col0, #T_ce07c_row2_col1, #T_ce07c_row2_col2, #T_ce07c_row7_col2, #T_ce07c_row8_col2, #T_ce07c_row9_col2 {\n  font-weight: bold;\n}\n</style>\n<table id=\"T_ce07c\">\n  <thead>\n    <tr>\n      <th class=\"blank level0\" >&nbsp;</th>\n      <th id=\"T_ce07c_level0_col0\" class=\"col_heading level0 col0\" >Validation Set MSE</th>\n      <th id=\"T_ce07c_level0_col1\" class=\"col_heading level0 col1\" >Validation Set RMSE</th>\n      <th id=\"T_ce07c_level0_col2\" class=\"col_heading level0 col2\" >Validation Set MAE</th>\n    </tr>\n    <tr>\n      <th class=\"index_name level0\" >Model</th>\n      <th class=\"blank col0\" >&nbsp;</th>\n      <th class=\"blank col1\" >&nbsp;</th>\n      <th class=\"blank col2\" >&nbsp;</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th id=\"T_ce07c_level0_row0\" class=\"row_heading level0 row0\" >Dummy Mean</th>\n      <td id=\"T_ce07c_row0_col0\" class=\"data row0 col0\" >3.78</td>\n      <td id=\"T_ce07c_row0_col1\" class=\"data row0 col1\" >1.94</td>\n      <td id=\"T_ce07c_row0_col2\" class=\"data row0 col2\" >1.80</td>\n    </tr>\n    <tr>\n      <th id=\"T_ce07c_level0_row1\" class=\"row_heading level0 row1\" >Dummy Median</th>\n      <td id=\"T_ce07c_row1_col0\" class=\"data row1 col0\" >2.50</td>\n      <td id=\"T_ce07c_row1_col1\" class=\"data row1 col1\" >1.58</td>\n      <td id=\"T_ce07c_row1_col2\" class=\"data row1 col2\" >1.40</td>\n    </tr>\n    <tr>\n      <th id=\"T_ce07c_level0_row2\" class=\"row_heading level0 row2\" >Dummy Quantile</th>\n      <td id=\"T_ce07c_row2_col0\" class=\"data row2 col0\" >1.24</td>\n      <td id=\"T_ce07c_row2_col1\" class=\"data row2 col1\" >1.11</td>\n      <td id=\"T_ce07c_row2_col2\" class=\"data row2 col2\" >0.78</td>\n    </tr>\n    <tr>\n      <th id=\"T_ce07c_level0_row3\" class=\"row_heading level0 row3\" >Linear Regression</th>\n      <td id=\"T_ce07c_row3_col0\" class=\"data row3 col0\" >7261011912780375.00</td>\n      <td id=\"T_ce07c_row3_col1\" class=\"data row3 col1\" >85211571.47</td>\n      <td id=\"T_ce07c_row3_col2\" class=\"data row3 col2\" >563569.30</td>\n    </tr>\n    <tr>\n      <th id=\"T_ce07c_level0_row4\" class=\"row_heading level0 row4\" >Lasso Regression</th>\n      <td id=\"T_ce07c_row4_col0\" class=\"data row4 col0\" >3.78</td>\n      <td id=\"T_ce07c_row4_col1\" class=\"data row4 col1\" >1.94</td>\n      <td id=\"T_ce07c_row4_col2\" class=\"data row4 col2\" >1.80</td>\n    </tr>\n    <tr>\n      <th id=\"T_ce07c_level0_row5\" class=\"row_heading level0 row5\" >Ridge Regression</th>\n      <td id=\"T_ce07c_row5_col0\" class=\"data row5 col0\" >2.93</td>\n      <td id=\"T_ce07c_row5_col1\" class=\"data row5 col1\" >1.71</td>\n      <td id=\"T_ce07c_row5_col2\" class=\"data row5 col2\" >1.44</td>\n    </tr>\n    <tr>\n      <th id=\"T_ce07c_level0_row6\" class=\"row_heading level0 row6\" >Elastic Net Regression</th>\n      <td id=\"T_ce07c_row6_col0\" class=\"data row6 col0\" >3.76</td>\n      <td id=\"T_ce07c_row6_col1\" class=\"data row6 col1\" >1.94</td>\n      <td id=\"T_ce07c_row6_col2\" class=\"data row6 col2\" >1.80</td>\n    </tr>\n    <tr>\n      <th id=\"T_ce07c_level0_row7\" class=\"row_heading level0 row7\" >Decision Tree Regression</th>\n      <td id=\"T_ce07c_row7_col0\" class=\"data row7 col0\" >6.68</td>\n      <td id=\"T_ce07c_row7_col1\" class=\"data row7 col1\" >2.58</td>\n      <td id=\"T_ce07c_row7_col2\" class=\"data row7 col2\" >1.14</td>\n    </tr>\n    <tr>\n      <th id=\"T_ce07c_level0_row8\" class=\"row_heading level0 row8\" >Random Forest Regression</th>\n      <td id=\"T_ce07c_row8_col0\" class=\"data row8 col0\" >2.46</td>\n      <td id=\"T_ce07c_row8_col1\" class=\"data row8 col1\" >1.57</td>\n      <td id=\"T_ce07c_row8_col2\" class=\"data row8 col2\" >1.12</td>\n    </tr>\n    <tr>\n      <th id=\"T_ce07c_level0_row9\" class=\"row_heading level0 row9\" >Gradient Boosting Regression</th>\n      <td id=\"T_ce07c_row9_col0\" class=\"data row9 col0\" >2.53</td>\n      <td id=\"T_ce07c_row9_col1\" class=\"data row9 col1\" >1.59</td>\n      <td id=\"T_ce07c_row9_col2\" class=\"data row9 col2\" >1.34</td>\n    </tr>\n  </tbody>\n</table>\n"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def bold_below_threshold(val):\n",
    "    if val <= 1.41:\n",
    "        return 'font-weight: bold'\n",
    "    else:\n",
    "        return ''\n",
    "\n",
    "val_metrics_df = pd.DataFrame(\n",
    "    val_results,\n",
    "    columns=['Model', 'Validation Set MSE', 'Validation Set RMSE', 'Validation Set MAE']\n",
    ")\n",
    "val_metrics_df.set_index('Model').style.format(precision=2).applymap(bold_below_threshold)\n",
    "# Not as good as Dummy Quantile, but superior to Dummy Median.\n",
    "# Almost in between the two.\n",
    "# MAEs much closer to Quantile vs. MSEs."
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-14T15:12:05.799694579Z",
     "start_time": "2023-08-14T15:12:05.799060614Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "___\n",
    "# Hyperparameter tuning\n",
    "\n",
    "The process of using randomized search to define a narrower space for grid search is illustrated here:\n",
    "\n",
    "[https://towardsdatascience.com/hyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74](https://towardsdatascience.com/hyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74)\n",
    "\n",
    "Code examples used from this article were used to complete the hyperparameter tuning process.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "# List of top 18 features by importance:\n",
    "# selected_features = [\n",
    "#     'Days Since Creation',\n",
    "#     'Days Since Last Logon',\n",
    "#     'BIOSReleaseAge',\n",
    "#     'LastBootAge',\n",
    "#     'avg_software_age',\n",
    "#     'FreeSpace_GB',\n",
    "#     'num_installed_programs',\n",
    "#     'Outlookx86_addin_filesize',\n",
    "#     'Outlookx64_addin_filesize',\n",
    "#     'Excelx86_addin_filesize',\n",
    "#     'PowerPointx86_addin_filesize',\n",
    "#     'Wordx64_addin_filesize',\n",
    "#     'has_cap_iq_add',\n",
    "#     'has_factset_add',\n",
    "#     'InstallAge',\n",
    "#     'num_users',\n",
    "#     'num_updates',\n",
    "#     'Total RAM'\n",
    "# ]\n",
    "\n",
    "# List of top 12 features by importance:\n",
    "selected_features = [\n",
    "    'Days Since Creation',\n",
    "    'avg_software_age',\n",
    "    'FreeSpace_GB',\n",
    "    'Outlookx86_addin_filesize',\n",
    "    'Wordx64_addin_filesize',\n",
    "    'Days Since Last Logon',\n",
    "    'num_installed_programs',\n",
    "    'Outlookx64_addin_filesize',\n",
    "    'InstallAge',\n",
    "    'LastBootAge',\n",
    "    'Excelx86_addin_filesize',\n",
    "    'has_cap_iq_add'\n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-14T15:12:05.799958546Z",
     "start_time": "2023-08-14T15:12:05.799568930Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "# Create trimmed datasets\n",
    "X_train_trimmed = X_train[selected_features]\n",
    "X_test_trimmed = X_test[selected_features]\n",
    "X_val_trimmed = X_val[selected_features]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-14T15:12:05.800075653Z",
     "start_time": "2023-08-14T15:12:05.799883854Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(78592, 12)\n",
      "(45722, 12)\n",
      "(45723, 12)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_trimmed.shape)\n",
    "print(X_test_trimmed.shape)\n",
    "print(X_val_trimmed.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-14T15:12:05.801758925Z",
     "start_time": "2023-08-14T15:12:05.800158294Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "# Define the custom scoring function\n",
    "def weighted_mae_fun(y_true, y_pred):\n",
    "    \"\"\"Scores by WMAE for cross_val_score()\n",
    "\n",
    "    # Errors for 0 num events are 0.5 times as important.\n",
    "    # Errors for 1 num events are 1 times as important.\n",
    "    # Errors for 2 or more num events are 3 times as important.\n",
    "    \"\"\"\n",
    "    errors = np.abs(y_true - y_pred)\n",
    "    sample_weights = np.where(y_true == 0, 0.5, np.where(y_true == 1, 1, 3))\n",
    "    weighted_errors = sample_weights * errors\n",
    "    weighted_mae_score = np.sum(weighted_errors) / np.sum(sample_weights)\n",
    "\n",
    "    return np.mean(weighted_mae_score)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-14T15:12:05.801888111Z",
     "start_time": "2023-08-14T15:12:05.800489847Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "#### RF: RandomizedSearchCV\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators [200, 300, 400, 500, 600]\n",
      "max_features ['sqrt', 'log2']\n",
      "max_depth [50, 100, 150, 200, 250, 300, None]\n",
      "min_samples_split [2, 3, 5, 10, 20, 40]\n",
      "min_samples_leaf [1, 3, 5, 10, 20, 40, 60, 80]\n",
      "bootstrap [True, False]\n"
     ]
    }
   ],
   "source": [
    "# Use the RandomizedSearchCV method on a RandomForestRegressor model\n",
    "# to identify a subset of parameters which could be optimal.\n",
    "\n",
    "# Process for building the hyperparameter grid below is derived from\n",
    "# the TowardsDataScience article linked above,\n",
    "# under \"Random Hyperparameter Grid\" section.\n",
    "\n",
    "# Number of trees in random forest.\n",
    "n_estimators = [int(x) for x in np.linspace(start=200, stop=600, num=5)] # Structure borrowed from TDS article.\n",
    "max_features = ['sqrt', 'log2']  # Number of features to consider at every split. Structure borrowed from TDS article.\n",
    "\n",
    "max_depth = [int(x) for x in np.linspace(50, 300, num=6)]  # Maximum number of levels in tree. Structure borrowed from TDS article.\n",
    "max_depth.append(None) # Add None. Structure borrowed from TDS article.\n",
    "\n",
    "min_samples_split = [2, 3, 5, 10, 20, 40]  # Minimum number of samples required to split a node. Structure borrowed from TDS article.\n",
    "min_samples_leaf = [1, 3, 5, 10, 20, 40, 60, 80]  # Minimum number of samples required at each leaf node. Structure borrowed from TDS article.\n",
    "bootstrap = [True, False]  # Method of selecting samples for training each tree. Structure borrowed from TDS article.\n",
    "\n",
    "# Create the random grid.\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "\n",
    "for k, v in random_grid.items():\n",
    "    print(k, v)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-14T15:12:05.802073795Z",
     "start_time": "2023-08-14T15:12:05.800723513Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "def evaluate_wmae(model, x, y): # Structure borrowed from TDS article.\n",
    "    \"\"\"\n",
    "    Built off alternate version for MAPE in TDS article linked above.\n",
    "\n",
    "    Extends weighted_mae_fun out one level by asking the model to create\n",
    "    predictions off x vs. handing them directly to weighted_mae_fun as\n",
    "    y_pred.\n",
    "    \"\"\"\n",
    "    preds = model.predict(x) # Structure borrowed from TDS article.\n",
    "    weighted_errors = weighted_mae_fun(y, preds) # Structure borrowed from TDS article.\n",
    "    print('Weighted Mean Absolute Error: {:0.2f}.'.format(weighted_errors)) # Structure borrowed from TDS article.\n",
    "    return weighted_errors # Structure borrowed from TDS article."
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-14T15:12:05.802176265Z",
     "start_time": "2023-08-14T15:12:05.800981424Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted Mean Absolute Error: 1.21.\n"
     ]
    }
   ],
   "source": [
    "base_rf = RandomForestRegressor(\n",
    "    n_estimators=10,\n",
    "    # random_state=42\n",
    ") # Structure borrowed from TDS article.\n",
    "base_rf.fit(X_train_trimmed, y_train) # Structure borrowed from TDS article.\n",
    "base_accuracy = evaluate_wmae(base_rf, X_val_trimmed, y_val) # Structure borrowed from TDS article."
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-14T15:12:11.254598477Z",
     "start_time": "2023-08-14T15:12:05.801189714Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[41], line 13\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;66;03m# Random search of parameters, using 3-fold cross validation.\u001B[39;00m\n\u001B[1;32m      3\u001B[0m rf_random \u001B[38;5;241m=\u001B[39m RandomizedSearchCV(\n\u001B[1;32m      4\u001B[0m     estimator\u001B[38;5;241m=\u001B[39mrf,\n\u001B[1;32m      5\u001B[0m     param_distributions\u001B[38;5;241m=\u001B[39mrandom_grid,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     11\u001B[0m     verbose\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m,\n\u001B[1;32m     12\u001B[0m )\n\u001B[0;32m---> 13\u001B[0m rf_random\u001B[38;5;241m.\u001B[39mfit(X_train_trimmed, y_train) \u001B[38;5;66;03m# Fit the random search model\u001B[39;00m\n\u001B[1;32m     14\u001B[0m rf_random\u001B[38;5;241m.\u001B[39mbest_params_\n",
      "File \u001B[0;32m~/anaconda3/envs/ff_env/lib/python3.11/site-packages/sklearn/base.py:1151\u001B[0m, in \u001B[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001B[0;34m(estimator, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1144\u001B[0m     estimator\u001B[38;5;241m.\u001B[39m_validate_params()\n\u001B[1;32m   1146\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[1;32m   1147\u001B[0m     skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[1;32m   1148\u001B[0m         prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[1;32m   1149\u001B[0m     )\n\u001B[1;32m   1150\u001B[0m ):\n\u001B[0;32m-> 1151\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fit_method(estimator, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m~/anaconda3/envs/ff_env/lib/python3.11/site-packages/sklearn/model_selection/_search.py:898\u001B[0m, in \u001B[0;36mBaseSearchCV.fit\u001B[0;34m(self, X, y, groups, **fit_params)\u001B[0m\n\u001B[1;32m    892\u001B[0m     results \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_format_results(\n\u001B[1;32m    893\u001B[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001B[1;32m    894\u001B[0m     )\n\u001B[1;32m    896\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m results\n\u001B[0;32m--> 898\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_run_search(evaluate_candidates)\n\u001B[1;32m    900\u001B[0m \u001B[38;5;66;03m# multimetric is determined here because in the case of a callable\u001B[39;00m\n\u001B[1;32m    901\u001B[0m \u001B[38;5;66;03m# self.scoring the return type is only known after calling\u001B[39;00m\n\u001B[1;32m    902\u001B[0m first_test_score \u001B[38;5;241m=\u001B[39m all_out[\u001B[38;5;241m0\u001B[39m][\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtest_scores\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n",
      "File \u001B[0;32m~/anaconda3/envs/ff_env/lib/python3.11/site-packages/sklearn/model_selection/_search.py:1806\u001B[0m, in \u001B[0;36mRandomizedSearchCV._run_search\u001B[0;34m(self, evaluate_candidates)\u001B[0m\n\u001B[1;32m   1804\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_run_search\u001B[39m(\u001B[38;5;28mself\u001B[39m, evaluate_candidates):\n\u001B[1;32m   1805\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001B[39;00m\n\u001B[0;32m-> 1806\u001B[0m     evaluate_candidates(\n\u001B[1;32m   1807\u001B[0m         ParameterSampler(\n\u001B[1;32m   1808\u001B[0m             \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mparam_distributions, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_iter, random_state\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrandom_state\n\u001B[1;32m   1809\u001B[0m         )\n\u001B[1;32m   1810\u001B[0m     )\n",
      "File \u001B[0;32m~/anaconda3/envs/ff_env/lib/python3.11/site-packages/sklearn/model_selection/_search.py:845\u001B[0m, in \u001B[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001B[0;34m(candidate_params, cv, more_results)\u001B[0m\n\u001B[1;32m    837\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mverbose \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m    838\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\n\u001B[1;32m    839\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFitting \u001B[39m\u001B[38;5;132;01m{0}\u001B[39;00m\u001B[38;5;124m folds for each of \u001B[39m\u001B[38;5;132;01m{1}\u001B[39;00m\u001B[38;5;124m candidates,\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    840\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m totalling \u001B[39m\u001B[38;5;132;01m{2}\u001B[39;00m\u001B[38;5;124m fits\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\n\u001B[1;32m    841\u001B[0m             n_splits, n_candidates, n_candidates \u001B[38;5;241m*\u001B[39m n_splits\n\u001B[1;32m    842\u001B[0m         )\n\u001B[1;32m    843\u001B[0m     )\n\u001B[0;32m--> 845\u001B[0m out \u001B[38;5;241m=\u001B[39m parallel(\n\u001B[1;32m    846\u001B[0m     delayed(_fit_and_score)(\n\u001B[1;32m    847\u001B[0m         clone(base_estimator),\n\u001B[1;32m    848\u001B[0m         X,\n\u001B[1;32m    849\u001B[0m         y,\n\u001B[1;32m    850\u001B[0m         train\u001B[38;5;241m=\u001B[39mtrain,\n\u001B[1;32m    851\u001B[0m         test\u001B[38;5;241m=\u001B[39mtest,\n\u001B[1;32m    852\u001B[0m         parameters\u001B[38;5;241m=\u001B[39mparameters,\n\u001B[1;32m    853\u001B[0m         split_progress\u001B[38;5;241m=\u001B[39m(split_idx, n_splits),\n\u001B[1;32m    854\u001B[0m         candidate_progress\u001B[38;5;241m=\u001B[39m(cand_idx, n_candidates),\n\u001B[1;32m    855\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mfit_and_score_kwargs,\n\u001B[1;32m    856\u001B[0m     )\n\u001B[1;32m    857\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m (cand_idx, parameters), (split_idx, (train, test)) \u001B[38;5;129;01min\u001B[39;00m product(\n\u001B[1;32m    858\u001B[0m         \u001B[38;5;28menumerate\u001B[39m(candidate_params), \u001B[38;5;28menumerate\u001B[39m(cv\u001B[38;5;241m.\u001B[39msplit(X, y, groups))\n\u001B[1;32m    859\u001B[0m     )\n\u001B[1;32m    860\u001B[0m )\n\u001B[1;32m    862\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(out) \u001B[38;5;241m<\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m    863\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    864\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNo fits were performed. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    865\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWas the CV iterator empty? \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    866\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWere there no candidates?\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    867\u001B[0m     )\n",
      "File \u001B[0;32m~/anaconda3/envs/ff_env/lib/python3.11/site-packages/sklearn/utils/parallel.py:65\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[0;34m(self, iterable)\u001B[0m\n\u001B[1;32m     60\u001B[0m config \u001B[38;5;241m=\u001B[39m get_config()\n\u001B[1;32m     61\u001B[0m iterable_with_config \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m     62\u001B[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001B[1;32m     63\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m delayed_func, args, kwargs \u001B[38;5;129;01min\u001B[39;00m iterable\n\u001B[1;32m     64\u001B[0m )\n\u001B[0;32m---> 65\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__call__\u001B[39m(iterable_with_config)\n",
      "File \u001B[0;32m~/anaconda3/envs/ff_env/lib/python3.11/site-packages/joblib/parallel.py:1098\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[0;34m(self, iterable)\u001B[0m\n\u001B[1;32m   1095\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_iterating \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[1;32m   1097\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backend\u001B[38;5;241m.\u001B[39mretrieval_context():\n\u001B[0;32m-> 1098\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mretrieve()\n\u001B[1;32m   1099\u001B[0m \u001B[38;5;66;03m# Make sure that we get a last message telling us we are done\u001B[39;00m\n\u001B[1;32m   1100\u001B[0m elapsed_time \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime() \u001B[38;5;241m-\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_start_time\n",
      "File \u001B[0;32m~/anaconda3/envs/ff_env/lib/python3.11/site-packages/joblib/parallel.py:975\u001B[0m, in \u001B[0;36mParallel.retrieve\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    973\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    974\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backend, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124msupports_timeout\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;28;01mFalse\u001B[39;00m):\n\u001B[0;32m--> 975\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_output\u001B[38;5;241m.\u001B[39mextend(job\u001B[38;5;241m.\u001B[39mget(timeout\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtimeout))\n\u001B[1;32m    976\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    977\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_output\u001B[38;5;241m.\u001B[39mextend(job\u001B[38;5;241m.\u001B[39mget())\n",
      "File \u001B[0;32m~/anaconda3/envs/ff_env/lib/python3.11/site-packages/joblib/_parallel_backends.py:567\u001B[0m, in \u001B[0;36mLokyBackend.wrap_future_result\u001B[0;34m(future, timeout)\u001B[0m\n\u001B[1;32m    564\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001B[39;00m\n\u001B[1;32m    565\u001B[0m \u001B[38;5;124;03mAsyncResults.get from multiprocessing.\"\"\"\u001B[39;00m\n\u001B[1;32m    566\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 567\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m future\u001B[38;5;241m.\u001B[39mresult(timeout\u001B[38;5;241m=\u001B[39mtimeout)\n\u001B[1;32m    568\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m CfTimeoutError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    569\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTimeoutError\u001B[39;00m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01me\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/envs/ff_env/lib/python3.11/concurrent/futures/_base.py:451\u001B[0m, in \u001B[0;36mFuture.result\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    448\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_state \u001B[38;5;241m==\u001B[39m FINISHED:\n\u001B[1;32m    449\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m__get_result()\n\u001B[0;32m--> 451\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_condition\u001B[38;5;241m.\u001B[39mwait(timeout)\n\u001B[1;32m    453\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_state \u001B[38;5;129;01min\u001B[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001B[1;32m    454\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m CancelledError()\n",
      "File \u001B[0;32m~/anaconda3/envs/ff_env/lib/python3.11/threading.py:320\u001B[0m, in \u001B[0;36mCondition.wait\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    318\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:    \u001B[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001B[39;00m\n\u001B[1;32m    319\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m timeout \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 320\u001B[0m         waiter\u001B[38;5;241m.\u001B[39macquire()\n\u001B[1;32m    321\u001B[0m         gotit \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m    322\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "rf = RandomForestRegressor() # First create the base model to tune.\n",
    "# Random search of parameters, using 3-fold cross validation.\n",
    "rf_random = RandomizedSearchCV(\n",
    "    estimator=rf,\n",
    "    param_distributions=random_grid,\n",
    "    n_iter=100, # Search across n_iter different random combinations.\n",
    "    cv=3,\n",
    "    scoring=make_scorer(weighted_mae_fun, greater_is_better=False),\n",
    "    random_state=42,\n",
    "    n_jobs=-1, # Use all available cores.\n",
    "    verbose=2, # Show progress\n",
    ") # Structure borrowed from TDS article.\n",
    "rf_random.fit(X_train_trimmed, y_train) # Fit the random search model. From TDS article.\n",
    "rf_random.best_params_ # From TDS article."
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-14T15:13:19.169621346Z",
     "start_time": "2023-08-14T15:12:11.257302451Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "best_random = rf_random.best_estimator_ # From TDS article.\n",
    "random_accuracy = evaluate_wmae(best_random, X_val_trimmed, y_val) # From TDS article."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Save best RandomizedSearchCV() params for WMAE: 1.12, n_iter=100:\n",
    "# {'n_estimators': 400,\n",
    "#  'min_samples_split': 2,\n",
    "#  'min_samples_leaf': 5,\n",
    "#  'max_features': 'log2',\n",
    "#  'max_depth': 250,\n",
    "#  'bootstrap': False}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "#### RF: GridSearchCV\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "param_grid = rf_random.best_params_.copy()\n",
    "param_grid"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "param_grid = {'n_estimators': 400,\n",
    " 'min_samples_split': 2,\n",
    " 'min_samples_leaf': 5,\n",
    " 'max_features': 'log2',\n",
    " 'max_depth': 250,\n",
    " 'bootstrap': False\n",
    " }"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-14T15:13:37.967205661Z",
     "start_time": "2023-08-14T15:13:37.924634289Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "data": {
      "text/plain": "{'n_estimators': [350, 400, 450],\n 'min_samples_split': [2, 5, 8],\n 'min_samples_leaf': [5, 8, 11],\n 'max_features': ['log2'],\n 'max_depth': [240, 250, 260],\n 'bootstrap': [False]}"
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def build_params(begin, end, amount, var):\n",
    "    \"\"\"\n",
    "    Extrapolated param grid build idea from random search\n",
    "    to automatically populate a smaller space for grid search.\n",
    "\n",
    "    'min_samples_split' must be greater than 1.\n",
    "    'min_samples_leaf' must be greater than 0.\n",
    "\n",
    "    :param begin: Place at which to begin.\n",
    "    :param end: Place at which to stop.\n",
    "    :param amount: By how much to shift for each iteration.\n",
    "    :param var: Which variable within the param_grid to build values for.\n",
    "    :return: A list of new values to enter into a dictionary that is passed to grid search.\n",
    "    \"\"\"\n",
    "    if param_grid[var] == 1:\n",
    "        return [1, 2, 3]\n",
    "    elif var == 'min_samples_split' and param_grid[var] < 2:\n",
    "        return [2, 3, 4]\n",
    "    elif var == 'max_depth' and param_grid[var] is None:\n",
    "        return [None]\n",
    "    elif var == 'max_depth' and param_grid[var] < 30:\n",
    "        return [10, 20, 30, 40, 50]\n",
    "    else:\n",
    "        new_list = [param_grid[var] - (amount * i) for i in range(begin, 0, -1)]\n",
    "        new_list.append(param_grid[var])\n",
    "        new_list.extend(param_grid[var] + (amount * i) for i in range(1, end))\n",
    "        return new_list\n",
    "\n",
    "# Take what RandomizedSearchCV found and expand the space around those variables to pass to GridSearchCV.\n",
    "param_grid.update({\n",
    "    'n_estimators': build_params(1, 2, 50, var='n_estimators'),\n",
    "    'min_samples_split': build_params(0, 3, 3, var='min_samples_split'),\n",
    "    'min_samples_leaf': build_params(0, 3, 3, var='min_samples_leaf'),\n",
    "    'max_features': [param_grid['max_features']],\n",
    "    'max_depth': build_params(1, 2, 10, var='max_depth'),\n",
    "    'bootstrap': [param_grid['bootstrap']]\n",
    "})\n",
    "\n",
    "# param_grid['n_estimators'].extend([int(param_grid['n_estimators'][-1] * 1.5)]) # Add a relatively large value.\n",
    "# param_grid['max_depth'].append(None)\n",
    "param_grid"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-14T15:13:40.098776607Z",
     "start_time": "2023-08-14T15:13:40.073294984Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 81 fits @ n_estimators=400 = 8m.\n",
    "base_rf_regressor = RandomForestRegressor()\n",
    "grid_search_rf = GridSearchCV(\n",
    "    base_rf_regressor,\n",
    "    param_grid,\n",
    "    scoring=make_scorer(weighted_mae_fun, greater_is_better=False),\n",
    "    cv=3,\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "grid_search_rf.fit(X_train_trimmed, y_train)\n",
    "best_rf_model_tuned = grid_search_rf.best_estimator_\n",
    "best_rf_model_tuned"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "grid_search_rf.best_params_"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "# Save final model:\n",
    "final_model = {'bootstrap': False,\n",
    " 'max_depth': 250,\n",
    " 'max_features': 'log2',\n",
    " 'min_samples_leaf': 5,\n",
    " 'min_samples_split': 2,\n",
    " 'n_estimators': 450}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-14T15:13:43.886338569Z",
     "start_time": "2023-08-14T15:13:43.870011698Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "gridsearch_accuracy = evaluate_wmae(best_rf_model_tuned, X_val_trimmed, y_val)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "#### Evaluate on held-out test set\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted Mean Absolute Error: 1.11.\n"
     ]
    },
    {
     "data": {
      "text/plain": "1.114725202563421"
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_test = RandomForestRegressor(**final_model)\n",
    "rf_test.fit(X_train_trimmed, y_train)\n",
    "evaluate_wmae(rf_test, X_test_trimmed, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-14T15:15:14.191459456Z",
     "start_time": "2023-08-14T15:13:57.022518678Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# RJ 08/13: One-time run: Observe how well the model performs on the test set.\n",
    "evaluate_wmae(best_rf_model_tuned, X_test_trimmed, y_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "# Re-define models for WMAE test results\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "models = {\n",
    "    'Dummy Mean': dummy_regressor_mean,\n",
    "    'Dummy Median': dummy_regressor_median,\n",
    "    'Dummy Quantile': dummy_regressor_quantile,\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Lasso Regression': Lasso(),\n",
    "    'Ridge Regression': Ridge(),\n",
    "    'Elastic Net Regression': ElasticNet(),\n",
    "    'Decision Tree Regression': DecisionTreeRegressor(),\n",
    "    'Random Forest Regression': rf_test,\n",
    "    'Gradient Boosting Regression': GradientBoostingRegressor()\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-14T15:15:17.959104037Z",
     "start_time": "2023-08-14T15:15:17.936048858Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "# Evaluate each model on the test set\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted Mean Absolute Error: 1.66.\n",
      "Weighted Mean Absolute Error: 1.40.\n",
      "Weighted Mean Absolute Error: 1.05.\n",
      "Weighted Mean Absolute Error: 1.55.\n",
      "Weighted Mean Absolute Error: 1.60.\n",
      "Weighted Mean Absolute Error: 1.55.\n",
      "Weighted Mean Absolute Error: 1.60.\n",
      "Weighted Mean Absolute Error: 1.27.\n",
      "Weighted Mean Absolute Error: 1.11.\n",
      "Weighted Mean Absolute Error: 1.37.\n"
     ]
    }
   ],
   "source": [
    "test_results = []\n",
    "for model_name, model in models.items():\n",
    "    model.fit(X_train_trimmed, y_train)\n",
    "    predictions_test = model.predict(X_test_trimmed)\n",
    "\n",
    "    mse_test = mean_squared_error(y_test, predictions_test)\n",
    "    rmse_test = np.sqrt(mse_test)\n",
    "    mae_test = mean_absolute_error(y_test, predictions_test)\n",
    "    wmae_test = evaluate_wmae(model, X_test_trimmed, y_test)\n",
    "\n",
    "    test_results.append([model_name, mse_test, rmse_test, mae_test, wmae_test])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-14T15:19:13.041283906Z",
     "start_time": "2023-08-14T15:17:42.328711812Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "# Load results into a DataFrame\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "data": {
      "text/plain": "<pandas.io.formats.style.Styler at 0x7f65d582a650>",
      "text/html": "<style type=\"text/css\">\n#T_0e6ab_row2_col0, #T_0e6ab_row2_col1, #T_0e6ab_row2_col2, #T_0e6ab_row2_col3, #T_0e6ab_row7_col2, #T_0e6ab_row7_col3, #T_0e6ab_row8_col2, #T_0e6ab_row8_col3 {\n  font-weight: bold;\n}\n</style>\n<table id=\"T_0e6ab\">\n  <thead>\n    <tr>\n      <th class=\"blank level0\" >&nbsp;</th>\n      <th id=\"T_0e6ab_level0_col0\" class=\"col_heading level0 col0\" >Test Set MSE</th>\n      <th id=\"T_0e6ab_level0_col1\" class=\"col_heading level0 col1\" >Test Set RMSE</th>\n      <th id=\"T_0e6ab_level0_col2\" class=\"col_heading level0 col2\" >Test Set MAE</th>\n      <th id=\"T_0e6ab_level0_col3\" class=\"col_heading level0 col3\" >Test Set WMAE</th>\n    </tr>\n    <tr>\n      <th class=\"index_name level0\" >Model</th>\n      <th class=\"blank col0\" >&nbsp;</th>\n      <th class=\"blank col1\" >&nbsp;</th>\n      <th class=\"blank col2\" >&nbsp;</th>\n      <th class=\"blank col3\" >&nbsp;</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th id=\"T_0e6ab_level0_row0\" class=\"row_heading level0 row0\" >Dummy Mean</th>\n      <td id=\"T_0e6ab_row0_col0\" class=\"data row0 col0\" >3.68</td>\n      <td id=\"T_0e6ab_row0_col1\" class=\"data row0 col1\" >1.92</td>\n      <td id=\"T_0e6ab_row0_col2\" class=\"data row0 col2\" >1.81</td>\n      <td id=\"T_0e6ab_row0_col3\" class=\"data row0 col3\" >1.66</td>\n    </tr>\n    <tr>\n      <th id=\"T_0e6ab_level0_row1\" class=\"row_heading level0 row1\" >Dummy Median</th>\n      <td id=\"T_0e6ab_row1_col0\" class=\"data row1 col0\" >2.38</td>\n      <td id=\"T_0e6ab_row1_col1\" class=\"data row1 col1\" >1.54</td>\n      <td id=\"T_0e6ab_row1_col2\" class=\"data row1 col2\" >1.40</td>\n      <td id=\"T_0e6ab_row1_col3\" class=\"data row1 col3\" >1.40</td>\n    </tr>\n    <tr>\n      <th id=\"T_0e6ab_level0_row2\" class=\"row_heading level0 row2\" >Dummy Quantile</th>\n      <td id=\"T_0e6ab_row2_col0\" class=\"data row2 col0\" >1.10</td>\n      <td id=\"T_0e6ab_row2_col1\" class=\"data row2 col1\" >1.05</td>\n      <td id=\"T_0e6ab_row2_col2\" class=\"data row2 col2\" >0.78</td>\n      <td id=\"T_0e6ab_row2_col3\" class=\"data row2 col3\" >1.05</td>\n    </tr>\n    <tr>\n      <th id=\"T_0e6ab_level0_row3\" class=\"row_heading level0 row3\" >Linear Regression</th>\n      <td id=\"T_0e6ab_row3_col0\" class=\"data row3 col0\" >3.12</td>\n      <td id=\"T_0e6ab_row3_col1\" class=\"data row3 col1\" >1.77</td>\n      <td id=\"T_0e6ab_row3_col2\" class=\"data row3 col2\" >1.62</td>\n      <td id=\"T_0e6ab_row3_col3\" class=\"data row3 col3\" >1.55</td>\n    </tr>\n    <tr>\n      <th id=\"T_0e6ab_level0_row4\" class=\"row_heading level0 row4\" >Lasso Regression</th>\n      <td id=\"T_0e6ab_row4_col0\" class=\"data row4 col0\" >3.34</td>\n      <td id=\"T_0e6ab_row4_col1\" class=\"data row4 col1\" >1.83</td>\n      <td id=\"T_0e6ab_row4_col2\" class=\"data row4 col2\" >1.70</td>\n      <td id=\"T_0e6ab_row4_col3\" class=\"data row4 col3\" >1.60</td>\n    </tr>\n    <tr>\n      <th id=\"T_0e6ab_level0_row5\" class=\"row_heading level0 row5\" >Ridge Regression</th>\n      <td id=\"T_0e6ab_row5_col0\" class=\"data row5 col0\" >3.12</td>\n      <td id=\"T_0e6ab_row5_col1\" class=\"data row5 col1\" >1.77</td>\n      <td id=\"T_0e6ab_row5_col2\" class=\"data row5 col2\" >1.62</td>\n      <td id=\"T_0e6ab_row5_col3\" class=\"data row5 col3\" >1.55</td>\n    </tr>\n    <tr>\n      <th id=\"T_0e6ab_level0_row6\" class=\"row_heading level0 row6\" >Elastic Net Regression</th>\n      <td id=\"T_0e6ab_row6_col0\" class=\"data row6 col0\" >3.32</td>\n      <td id=\"T_0e6ab_row6_col1\" class=\"data row6 col1\" >1.82</td>\n      <td id=\"T_0e6ab_row6_col2\" class=\"data row6 col2\" >1.69</td>\n      <td id=\"T_0e6ab_row6_col3\" class=\"data row6 col3\" >1.60</td>\n    </tr>\n    <tr>\n      <th id=\"T_0e6ab_level0_row7\" class=\"row_heading level0 row7\" >Decision Tree Regression</th>\n      <td id=\"T_0e6ab_row7_col0\" class=\"data row7 col0\" >5.35</td>\n      <td id=\"T_0e6ab_row7_col1\" class=\"data row7 col1\" >2.31</td>\n      <td id=\"T_0e6ab_row7_col2\" class=\"data row7 col2\" >1.16</td>\n      <td id=\"T_0e6ab_row7_col3\" class=\"data row7 col3\" >1.27</td>\n    </tr>\n    <tr>\n      <th id=\"T_0e6ab_level0_row8\" class=\"row_heading level0 row8\" >Random Forest Regression</th>\n      <td id=\"T_0e6ab_row8_col0\" class=\"data row8 col0\" >1.98</td>\n      <td id=\"T_0e6ab_row8_col1\" class=\"data row8 col1\" >1.41</td>\n      <td id=\"T_0e6ab_row8_col2\" class=\"data row8 col2\" >1.10</td>\n      <td id=\"T_0e6ab_row8_col3\" class=\"data row8 col3\" >1.11</td>\n    </tr>\n    <tr>\n      <th id=\"T_0e6ab_level0_row9\" class=\"row_heading level0 row9\" >Gradient Boosting Regression</th>\n      <td id=\"T_0e6ab_row9_col0\" class=\"data row9 col0\" >2.60</td>\n      <td id=\"T_0e6ab_row9_col1\" class=\"data row9 col1\" >1.61</td>\n      <td id=\"T_0e6ab_row9_col2\" class=\"data row9 col2\" >1.42</td>\n      <td id=\"T_0e6ab_row9_col3\" class=\"data row9 col3\" >1.37</td>\n    </tr>\n  </tbody>\n</table>\n"
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def bold_below_threshold(val):\n",
    "    if val <= 1.3:\n",
    "        return 'font-weight: bold'\n",
    "    else:\n",
    "        return ''\n",
    "\n",
    "test_metrics_df = pd.DataFrame(\n",
    "    test_results,\n",
    "    columns=['Model', 'Test Set MSE', 'Test Set RMSE', 'Test Set MAE', 'Test Set WMAE']\n",
    ")\n",
    "test_metrics_df.set_index('Model').style.format(precision=2).applymap(bold_below_threshold)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-14T15:22:10.631281677Z",
     "start_time": "2023-08-14T15:22:10.585112577Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
