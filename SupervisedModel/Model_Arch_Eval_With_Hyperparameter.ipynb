{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-13T16:01:39.108084504Z",
     "start_time": "2023-08-13T16:01:38.699383147Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Pre-processing.\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Dummy.\n",
    "from sklearn.dummy import DummyRegressor\n",
    "\n",
    "# Models.\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge, ElasticNet\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "\n",
    "# Metrics.\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "# Evaluating.\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "# Step 1: Load data\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-13T16:01:39.137092998Z",
     "start_time": "2023-08-13T16:01:38.751588190Z"
    }
   },
   "outputs": [],
   "source": [
    "training_data = pd.read_parquet('./assets/training_set_v2.parquet')\n",
    "test_data = pd.read_parquet('./assets/test_set_v2.parquet')\n",
    "validation_data = pd.read_parquet('./assets/validation_set_v2.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "# Step 2: Standardize data\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [],
   "source": [
    "# Make sure y isn't in X.\n",
    "columns_to_drop = ['events', 'ItemKey', 'RWB_EFFECTIVE_DATE']\n",
    "X_train = training_data.drop(columns=columns_to_drop, axis=1)\n",
    "X_test = test_data.drop(columns=columns_to_drop, axis=1)\n",
    "X_val = validation_data.drop(columns=columns_to_drop, axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-13T16:01:39.215612574Z",
     "start_time": "2023-08-13T16:01:38.799689260Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [],
   "source": [
    "# Standardize values within each column to have a mean=0 and std=1.\n",
    "scaler = StandardScaler()\n",
    "X_train_std = scaler.fit_transform(X_train)\n",
    "X_test_std = scaler.transform(X_test)\n",
    "X_val_std = scaler.transform(X_val)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-13T16:01:40.758042359Z",
     "start_time": "2023-08-13T16:01:38.821717865Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [],
   "source": [
    "# Do not standardize y.\n",
    "y_train = training_data['events']\n",
    "y_test = test_data['events']\n",
    "y_val = validation_data['events']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-13T16:01:40.803807343Z",
     "start_time": "2023-08-13T16:01:40.803508005Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "# Step 3: Instantiate dummy regressors\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [],
   "source": [
    "dummy_regressor_mean = DummyRegressor(strategy='mean')\n",
    "dummy_regressor_median = DummyRegressor(strategy='median')\n",
    "dummy_regressor_quantile = DummyRegressor(strategy='quantile', quantile=0.25)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-13T16:01:40.806957006Z",
     "start_time": "2023-08-13T16:01:40.804017399Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "# Step 4: Define models\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [],
   "source": [
    "models = {\n",
    "    'Dummy Mean': dummy_regressor_mean,\n",
    "    'Dummy Median': dummy_regressor_median,\n",
    "    'Dummy Quantile': dummy_regressor_quantile,\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Lasso Regression': Lasso(),\n",
    "    'Ridge Regression': Ridge(),\n",
    "    'Elastic Net Regression': ElasticNet(),\n",
    "    'Decision Tree Regression': DecisionTreeRegressor(),\n",
    "    'Random Forest Regression': RandomForestRegressor(),\n",
    "    'Gradient Boosting Regression': GradientBoostingRegressor()\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-13T16:01:40.807289277Z",
     "start_time": "2023-08-13T16:01:40.804177958Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "# Step 5: Evaluate each model\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [],
   "source": [
    "test_results = []\n",
    "for model_name, model in models.items():\n",
    "    model.fit(X_train_std, y_train)\n",
    "    predictions_test = model.predict(X_test_std)\n",
    "\n",
    "    mse_test = mean_squared_error(y_test, predictions_test)\n",
    "    rmse_test = np.sqrt(mse_test)\n",
    "    mae_test = mean_absolute_error(y_test, predictions_test)\n",
    "\n",
    "    test_results.append([model_name, mse_test, rmse_test, mae_test])\n",
    "\n",
    "    # if model_name in ['Linear Regression', 'Lasso Regression', 'Ridge Regression', 'Elastic Net Regression', 'Decision Tree Regression', 'Random Forest Regression', 'Gradient Boosting Regression']:\n",
    "    #     if hasattr(model, 'coef_'):\n",
    "    #         feature_importances = model.coef_\n",
    "    #         sorted_indices = np.argsort(np.abs(feature_importances))[::-1][:5]\n",
    "    #     elif hasattr(model, 'feature_importances_'):\n",
    "    #         feature_importances = model.feature_importances_\n",
    "    #         sorted_indices = np.argsort(feature_importances)[::-1][:5]\n",
    "    #     else:\n",
    "    #         sorted_indices = None\n",
    "\n",
    "    #     if sorted_indices is not None:\n",
    "    #         print(f'Feature importances for {model_name}:')\n",
    "    #         for idx in sorted_indices:\n",
    "    #             feature_name = X_train.columns[idx]\n",
    "    #             importance = feature_importances[idx]\n",
    "    #             print(f'{feature_name}: {importance}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-13T16:03:53.184392177Z",
     "start_time": "2023-08-13T16:01:40.804331388Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "# Step 6: Load results into a DataFrame\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [
    {
     "data": {
      "text/plain": "<pandas.io.formats.style.Styler at 0x7f8a7e9df1f0>",
      "text/html": "<style type=\"text/css\">\n#T_faa1b_row1_col2, #T_faa1b_row2_col0, #T_faa1b_row2_col1, #T_faa1b_row2_col2, #T_faa1b_row7_col2, #T_faa1b_row8_col2, #T_faa1b_row9_col2 {\n  font-weight: bold;\n}\n</style>\n<table id=\"T_faa1b\">\n  <thead>\n    <tr>\n      <th class=\"blank level0\" >&nbsp;</th>\n      <th id=\"T_faa1b_level0_col0\" class=\"col_heading level0 col0\" >Test MSE</th>\n      <th id=\"T_faa1b_level0_col1\" class=\"col_heading level0 col1\" >Test RMSE</th>\n      <th id=\"T_faa1b_level0_col2\" class=\"col_heading level0 col2\" >Test MAE</th>\n    </tr>\n    <tr>\n      <th class=\"index_name level0\" >Model</th>\n      <th class=\"blank col0\" >&nbsp;</th>\n      <th class=\"blank col1\" >&nbsp;</th>\n      <th class=\"blank col2\" >&nbsp;</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th id=\"T_faa1b_level0_row0\" class=\"row_heading level0 row0\" >Dummy Mean</th>\n      <td id=\"T_faa1b_row0_col0\" class=\"data row0 col0\" >3.68</td>\n      <td id=\"T_faa1b_row0_col1\" class=\"data row0 col1\" >1.92</td>\n      <td id=\"T_faa1b_row0_col2\" class=\"data row0 col2\" >1.81</td>\n    </tr>\n    <tr>\n      <th id=\"T_faa1b_level0_row1\" class=\"row_heading level0 row1\" >Dummy Median</th>\n      <td id=\"T_faa1b_row1_col0\" class=\"data row1 col0\" >2.38</td>\n      <td id=\"T_faa1b_row1_col1\" class=\"data row1 col1\" >1.54</td>\n      <td id=\"T_faa1b_row1_col2\" class=\"data row1 col2\" >1.40</td>\n    </tr>\n    <tr>\n      <th id=\"T_faa1b_level0_row2\" class=\"row_heading level0 row2\" >Dummy Quantile</th>\n      <td id=\"T_faa1b_row2_col0\" class=\"data row2 col0\" >1.10</td>\n      <td id=\"T_faa1b_row2_col1\" class=\"data row2 col1\" >1.05</td>\n      <td id=\"T_faa1b_row2_col2\" class=\"data row2 col2\" >0.78</td>\n    </tr>\n    <tr>\n      <th id=\"T_faa1b_level0_row3\" class=\"row_heading level0 row3\" >Linear Regression</th>\n      <td id=\"T_faa1b_row3_col0\" class=\"data row3 col0\" >7261170719898101.00</td>\n      <td id=\"T_faa1b_row3_col1\" class=\"data row3 col1\" >85212503.31</td>\n      <td id=\"T_faa1b_row3_col2\" class=\"data row3 col2\" >563581.62</td>\n    </tr>\n    <tr>\n      <th id=\"T_faa1b_level0_row4\" class=\"row_heading level0 row4\" >Lasso Regression</th>\n      <td id=\"T_faa1b_row4_col0\" class=\"data row4 col0\" >3.68</td>\n      <td id=\"T_faa1b_row4_col1\" class=\"data row4 col1\" >1.92</td>\n      <td id=\"T_faa1b_row4_col2\" class=\"data row4 col2\" >1.81</td>\n    </tr>\n    <tr>\n      <th id=\"T_faa1b_level0_row5\" class=\"row_heading level0 row5\" >Ridge Regression</th>\n      <td id=\"T_faa1b_row5_col0\" class=\"data row5 col0\" >2.81</td>\n      <td id=\"T_faa1b_row5_col1\" class=\"data row5 col1\" >1.67</td>\n      <td id=\"T_faa1b_row5_col2\" class=\"data row5 col2\" >1.44</td>\n    </tr>\n    <tr>\n      <th id=\"T_faa1b_level0_row6\" class=\"row_heading level0 row6\" >Elastic Net Regression</th>\n      <td id=\"T_faa1b_row6_col0\" class=\"data row6 col0\" >3.66</td>\n      <td id=\"T_faa1b_row6_col1\" class=\"data row6 col1\" >1.91</td>\n      <td id=\"T_faa1b_row6_col2\" class=\"data row6 col2\" >1.80</td>\n    </tr>\n    <tr>\n      <th id=\"T_faa1b_level0_row7\" class=\"row_heading level0 row7\" >Decision Tree Regression</th>\n      <td id=\"T_faa1b_row7_col0\" class=\"data row7 col0\" >6.08</td>\n      <td id=\"T_faa1b_row7_col1\" class=\"data row7 col1\" >2.47</td>\n      <td id=\"T_faa1b_row7_col2\" class=\"data row7 col2\" >1.14</td>\n    </tr>\n    <tr>\n      <th id=\"T_faa1b_level0_row8\" class=\"row_heading level0 row8\" >Random Forest Regression</th>\n      <td id=\"T_faa1b_row8_col0\" class=\"data row8 col0\" >2.37</td>\n      <td id=\"T_faa1b_row8_col1\" class=\"data row8 col1\" >1.54</td>\n      <td id=\"T_faa1b_row8_col2\" class=\"data row8 col2\" >1.12</td>\n    </tr>\n    <tr>\n      <th id=\"T_faa1b_level0_row9\" class=\"row_heading level0 row9\" >Gradient Boosting Regression</th>\n      <td id=\"T_faa1b_row9_col0\" class=\"data row9 col0\" >2.42</td>\n      <td id=\"T_faa1b_row9_col1\" class=\"data row9 col1\" >1.55</td>\n      <td id=\"T_faa1b_row9_col2\" class=\"data row9 col2\" >1.34</td>\n    </tr>\n  </tbody>\n</table>\n"
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def bold_below_threshold(val):\n",
    "    if val <= 1.41:\n",
    "        return 'font-weight: bold'\n",
    "    else:\n",
    "        return ''\n",
    "\n",
    "test_metrics_df = pd.DataFrame(\n",
    "    test_results,\n",
    "    columns=['Model', 'Test MSE', 'Test RMSE', 'Test MAE']\n",
    ")\n",
    "test_metrics_df.set_index('Model').style.format(precision=2).applymap(bold_below_threshold)\n",
    "# Not as good as Dummy Quantile, but superior to Dummy Median.\n",
    "# Almost in between the two.\n",
    "# MAEs much closer to Quantile vs. MSEs."
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-13T16:03:53.194188387Z",
     "start_time": "2023-08-13T16:03:53.190200949Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-13T16:03:53.197449005Z",
     "start_time": "2023-08-13T16:03:53.194659413Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Include 5 fold cross val\n",
    "# test_results2 = []\n",
    "# for model_name, model in models.items():\n",
    "#     cv_scores = cross_val_score(model, X_train_std, training_data['events'], scoring='neg_mean_squared_error', cv=5)\n",
    "#     mse_cv = -np.mean(cv_scores)\n",
    "#     rmse_cv = np.sqrt(mse_cv)\n",
    "#     mae_cv = np.mean(cross_val_score(model, X_train_std, training_data['events'], scoring='neg_mean_absolute_error', cv=5))\n",
    "\n",
    "#     model.fit(X_train_std, training_data['events'])\n",
    "#     predictions_test = model.predict(X_test_std)\n",
    "#     mse_test = mean_squared_error(test_data['events'], predictions_test)\n",
    "#     rmse_test = np.sqrt(mse_test)\n",
    "#     mae_test = mean_absolute_error(test_data['events'], predictions_test)\n",
    "\n",
    "#     # if model_name in ['Linear Regression', 'Lasso Regression', 'Ridge Regression', 'Elastic Net Regression', 'Decision Tree Regression', 'Random Forest Regression', 'Gradient Boosting Regression']:\n",
    "#     #     if hasattr(model, 'coef_'):  \n",
    "#     #         feature_importances = model.coef_\n",
    "#     #         sorted_indices = np.argsort(np.abs(feature_importances))[::-1][:5]  \n",
    "#     #     elif hasattr(model, 'feature_importances_'):  \n",
    "#     #         feature_importances = model.feature_importances_\n",
    "#     #         sorted_indices = np.argsort(feature_importances)[::-1][:5]\n",
    "#     #     else:\n",
    "#     #         sorted_indices = None\n",
    "\n",
    "#     #     if sorted_indices is not None:\n",
    "#     #         print(f'Feature importances for {model_name}:')\n",
    "#     #         for idx in sorted_indices:\n",
    "#     #             feature_name = X_train.columns[idx]\n",
    "#     #             importance = feature_importances[idx]\n",
    "#     #             print(f'{feature_name}: {importance}')\n",
    "\n",
    "#     test_results2.append([model_name, mse_test, rmse_test, mae_test, mse_cv, rmse_cv, mae_cv])\n",
    "\n",
    "# test_metrics2_df = pd.DataFrame(test_results2, columns=['Model', 'Test MSE', 'Test RMSE', 'Test MAE', 'CV MSE', 'CV RMSE', 'CV MAE'])\n",
    "# test_metrics2_df"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "___\n",
    "# Hyperparameter tuning\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "# Original\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-13T16:03:53.251636593Z",
     "start_time": "2023-08-13T16:03:53.196831535Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Define hyperparameter grid for grid search\n",
    "# param_grid = {\n",
    "#     'n_estimators': [50, 100, 200],\n",
    "#     'max_depth': [None, 10, 20],\n",
    "#     'min_samples_split': [2, 5, 10],\n",
    "#     'min_samples_leaf': [1, 2, 4]\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-13T16:03:53.252273554Z",
     "start_time": "2023-08-13T16:03:53.242853832Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Define hyperparameter distributions for random search\n",
    "# param_dist = {\n",
    "#     'n_estimators': [50, 100, 200],\n",
    "#     'max_depth': [None, 10, 20],\n",
    "#     'min_samples_split': [2, 5, 10],\n",
    "#     'min_samples_leaf': [1, 2, 4]\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-13T16:03:53.252610730Z",
     "start_time": "2023-08-13T16:03:53.243111887Z"
    }
   },
   "outputs": [],
   "source": [
    "# Split data into training and validation sets\n",
    "# RJ 08/12: Cannot split on a column that has already received pre-processing: Data leakage.\n",
    "# X_train, X_val, y_train, y_val = train_test_split(\n",
    "#     X_train_std,\n",
    "#     training_data['events'],\n",
    "#     test_size=0.2,\n",
    "#     random_state=42\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [],
   "source": [
    "# # Initialize Random Forest model.\n",
    "# rf_model = RandomForestRegressor(random_state=42)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-13T16:03:53.252888210Z",
     "start_time": "2023-08-13T16:03:53.243321613Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [],
   "source": [
    "# # Random Search\n",
    "# random_search = RandomizedSearchCV(\n",
    "#     rf_model,\n",
    "#     param_distributions=param_dist,\n",
    "#     n_iter=10,\n",
    "#     scoring='neg_mean_squared_error',\n",
    "#     cv=5,\n",
    "#     random_state=42\n",
    "# )\n",
    "# random_search.fit(X_train, y_train)\n",
    "# best_params_random = random_search.best_params_\n",
    "# best_rf_random = random_search.best_estimator_"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-13T16:03:53.253044448Z",
     "start_time": "2023-08-13T16:03:53.243467563Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-13T16:03:53.253174165Z",
     "start_time": "2023-08-13T16:03:53.243620694Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Grid Search\n",
    "# grid_search = GridSearchCV(\n",
    "#     rf_model,\n",
    "#     param_grid,\n",
    "#     scoring='neg_mean_squared_error',\n",
    "#     cv=5\n",
    "# )\n",
    "# grid_search.fit(X_train, y_train)\n",
    "# best_params_grid = grid_search.best_params_\n",
    "# best_rf_grid = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-13T16:03:53.253341603Z",
     "start_time": "2023-08-13T16:03:53.243847422Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Evaluate best models on validation data\n",
    "# y_val_pred_grid = best_rf_grid.predict(X_val)\n",
    "# mse_val_grid = mean_squared_error(y_val, y_val_pred_grid)\n",
    "#\n",
    "# y_val_pred_random = best_rf_random.predict(X_val)\n",
    "# mse_val_random = mean_squared_error(y_val, y_val_pred_random)\n",
    "#\n",
    "# print(f'Grid Search - Best Hyperparameters: {best_params_grid}, Validation MSE: {mse_val_grid}')\n",
    "# print(f'Random Search - Best Hyperparameters: {best_params_random}, Validation MSE: {mse_val_random}')"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "# New\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [],
   "source": [
    "# List of selected features\n",
    "# selected_features = [\n",
    "#     'Days Since Creation',\n",
    "#     'Days Since Last Logon',\n",
    "#     'BIOSReleaseAge',\n",
    "#     'LastBootAge',\n",
    "#     'avg_software_age',\n",
    "#     'FreeSpace_GB',\n",
    "#     'num_installed_programs',\n",
    "#     'Outlookx86_addin_filesize',\n",
    "#     'Outlookx64_addin_filesize',\n",
    "#     'Excelx86_addin_filesize',\n",
    "#     'PowerPointx86_addin_filesize',\n",
    "#     'Wordx64_addin_filesize',\n",
    "#     'has_cap_iq_add',\n",
    "#     'has_factset_add',\n",
    "#     'InstallAge',\n",
    "#     'num_users',\n",
    "#     'num_updates',\n",
    "#     'Total RAM'\n",
    "# ]\n",
    "\n",
    "selected_features = [\n",
    "    'Days Since Creation',\n",
    "    'avg_software_age',\n",
    "    'FreeSpace_GB',\n",
    "    'Outlookx86_addin_filesize',\n",
    "    'Wordx64_addin_filesize',\n",
    "    'Days Since Last Logon',\n",
    "    'num_installed_programs',\n",
    "    'Outlookx64_addin_filesize',\n",
    "    'InstallAge',\n",
    "    'LastBootAge',\n",
    "    'Excelx86_addin_filesize',\n",
    "    'has_cap_iq_add'\n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-13T16:03:53.253480806Z",
     "start_time": "2023-08-13T16:03:53.243969722Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [],
   "source": [
    "# Create trimmed datasets\n",
    "X_train_trimmed = X_train[selected_features]\n",
    "X_test_trimmed = X_test[selected_features]\n",
    "X_val_trimmed = X_val[selected_features]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-13T16:03:53.253584627Z",
     "start_time": "2023-08-13T16:03:53.244078290Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(78592, 12)\n",
      "(45722, 12)\n",
      "(45723, 12)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_trimmed.shape)\n",
    "print(X_test_trimmed.shape)\n",
    "print(X_val_trimmed.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-13T16:03:53.253875156Z",
     "start_time": "2023-08-13T16:03:53.244181920Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [],
   "source": [
    "# def rmse_scorer(y_true, y_pred):\n",
    "#     \"\"\"Scores by Root Mean Square Error for cross_val_score()\"\"\"\n",
    "#     mse = mean_squared_error(y_true, y_pred)\n",
    "#     return np.sqrt(mse)\n",
    "\n",
    "\n",
    "# Define the custom scoring function\n",
    "def weighted_mae_fun(y_true, y_pred):\n",
    "    \"\"\"Scores by WMAE for cross_val_score()\n",
    "\n",
    "    # Errors for 0 num events are 0.5 times as important.\n",
    "    # Errors for 1 num events are 1 times as important.\n",
    "    # Errors for 2 or more num events are 3 times as important.\n",
    "    \"\"\"\n",
    "    errors = np.abs(y_true - y_pred)\n",
    "    sample_weights = np.where(y_true == 0, 0.5, np.where(y_true == 1, 1, 3))\n",
    "    weighted_errors = sample_weights * errors\n",
    "    weighted_mae_score = np.sum(weighted_errors) / np.sum(sample_weights)\n",
    "\n",
    "    return np.mean(weighted_mae_score)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-13T16:03:53.254029566Z",
     "start_time": "2023-08-13T16:03:53.244315637Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "#### RF: RandomizedSearchCV\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators [200, 300, 400, 500, 600]\n",
      "max_features ['sqrt', 'log2']\n",
      "max_depth [50, 100, 150, 200, 250, 300, None]\n",
      "min_samples_split [2, 3, 5, 10, 20, 40]\n",
      "min_samples_leaf [1, 3, 5, 10, 20, 40, 60, 80]\n",
      "bootstrap [True, False]\n"
     ]
    }
   ],
   "source": [
    "# Use the RandomizedSearchCV method on a RandomForestRegressor model to identify a subset of parameters which could be optimal.\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start=200, stop=600, num=5)]\n",
    "max_features = ['sqrt', 'log2']  # Number of features to consider at every split\n",
    "\n",
    "max_depth = [int(x) for x in np.linspace(50, 300, num=6)]  # Maximum number of levels in tree\n",
    "max_depth.append(None) # Add None.\n",
    "\n",
    "min_samples_split = [2, 3, 5, 10, 20, 40]  # Minimum number of samples required to split a node\n",
    "min_samples_leaf = [1, 3, 5, 10, 20, 40, 60, 80]  # Minimum number of samples required at each leaf node\n",
    "bootstrap = [True, False]  # Method of selecting samples for training each tree\n",
    "\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "for k, v in random_grid.items():\n",
    "    print(k, v)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-13T16:03:53.254233396Z",
     "start_time": "2023-08-13T16:03:53.244421097Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "outputs": [],
   "source": [
    "def evaluate_wmae(model, x, y):\n",
    "    \"\"\"\n",
    "    Extends weighted_mae_fun out one level by asking the model to create\n",
    "    predictions off x vs. handing them directly to weighted_mae_fun as\n",
    "    y_pred.\n",
    "    \"\"\"\n",
    "    preds = model.predict(x)\n",
    "    weighted_errors = weighted_mae_fun(y, preds)\n",
    "    print('Weighted Mean Absolute Error: {:0.2f}.'.format(weighted_errors))\n",
    "    return weighted_errors"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-13T16:03:53.254355984Z",
     "start_time": "2023-08-13T16:03:53.247476072Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted Mean Absolute Error: 1.45.\n"
     ]
    }
   ],
   "source": [
    "base_rf = RandomForestRegressor(\n",
    "    n_estimators=10,\n",
    "    criterion='poisson',\n",
    "    # random_state=42\n",
    ")\n",
    "base_rf.fit(X_train_trimmed, y_train)\n",
    "base_accuracy = evaluate_wmae(base_rf, X_val_trimmed, y_val)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-13T16:04:11.298094488Z",
     "start_time": "2023-08-13T16:03:53.252730754Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n",
      "[CV] END bootstrap=False, max_depth=50, max_features=sqrt, min_samples_leaf=60, min_samples_split=5, n_estimators=300; total time= 1.7min\n",
      "[CV] END bootstrap=False, max_depth=150, max_features=sqrt, min_samples_leaf=20, min_samples_split=2, n_estimators=400; total time= 3.4min\n",
      "[CV] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=5, min_samples_split=2, n_estimators=400; total time= 3.8min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rj/anaconda3/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py:702: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestRegressor(criterion='poisson') # First create the base model to tune.\n",
    "# Random search of parameters, using 3-fold cross validation.\n",
    "rf_random = RandomizedSearchCV(\n",
    "    estimator=rf,\n",
    "    param_distributions=random_grid,\n",
    "    n_iter=100, # Search across n_iter different random combinations.\n",
    "    cv=3,\n",
    "    scoring=make_scorer(weighted_mae_fun, greater_is_better=False),\n",
    "    random_state=42,\n",
    "    n_jobs=-1, # Use all available cores.\n",
    "    verbose=2,\n",
    ")\n",
    "rf_random.fit(X_train_trimmed, y_train) # Fit the random search model\n",
    "rf_random.best_params_"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2023-08-13T17:04:53.787829502Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted Mean Absolute Error: 1.12.\n"
     ]
    }
   ],
   "source": [
    "best_random = rf_random.best_estimator_\n",
    "random_accuracy = evaluate_wmae(best_random, X_val_trimmed, y_val)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-13T13:19:43.241652681Z",
     "start_time": "2023-08-13T13:19:40.355880133Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# WMAE: 1.12 from n_iter=100:\n",
    "# {'n_estimators': 400,\n",
    "#  'min_samples_split': 2,\n",
    "#  'min_samples_leaf': 5,\n",
    "#  'max_features': 'log2',\n",
    "#  'max_depth': 250,\n",
    "#  'bootstrap': False}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "#### RF: GridSearchCV\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "outputs": [
    {
     "data": {
      "text/plain": "{'n_estimators': 400,\n 'min_samples_split': 2,\n 'min_samples_leaf': 5,\n 'max_features': 'log2',\n 'max_depth': 250,\n 'bootstrap': False}"
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = rf_random.best_params_.copy()\n",
    "param_grid"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-13T16:07:21.295744144Z",
     "start_time": "2023-08-13T16:07:21.252108882Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "outputs": [],
   "source": [
    "# RJ 08/12: This took 8 mins. to run\n",
    "# param_grid_rf = {\n",
    "#     'n_estimators': [100, 200, 300],\n",
    "#     'max_depth': [5, 10, 20],\n",
    "#     'min_samples_split': [2, 5, 10]\n",
    "# }"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-13T16:07:21.587597980Z",
     "start_time": "2023-08-13T16:07:21.545008656Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "outputs": [
    {
     "data": {
      "text/plain": "{'n_estimators': [350, 400, 450],\n 'min_samples_split': [2, 5, 8],\n 'min_samples_leaf': [5, 8, 11],\n 'max_features': ['log2'],\n 'max_depth': [240, 250, 260],\n 'bootstrap': [False]}"
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def build_params(begin, end, amount, var):\n",
    "    \"\"\"\n",
    "    'min_samples_split' must be greater than 1.\n",
    "    'min_samples_leaf' must be greater than 0.\n",
    "\n",
    "    :param begin: Place at which to begin.\n",
    "    :param end: Place at which to stop.\n",
    "    :param amount: By how much to shift for each iteration.\n",
    "    :param var: Which variable within the param_grid to build values for.\n",
    "    :return: A list of new values to enter into a dictionary that is passed to grid search.\n",
    "    \"\"\"\n",
    "    if param_grid[var] == 1:\n",
    "        return [1, 2, 3]\n",
    "    elif var == 'min_samples_split' and param_grid[var] < 2:\n",
    "        return [2, 3, 4]\n",
    "    elif var == 'max_depth' and param_grid[var] is None:\n",
    "        return [None]\n",
    "    elif var == 'max_depth' and param_grid[var] < 30:\n",
    "        return [10, 20, 30, 40, 50]\n",
    "    else:\n",
    "        new_list = [param_grid[var] - (amount * i) for i in range(begin, 0, -1)]\n",
    "        new_list.append(param_grid[var])\n",
    "        new_list.extend(param_grid[var] + (amount * i) for i in range(1, end))\n",
    "        return new_list\n",
    "\n",
    "# Take what RandomizedSearchCV found and expand the space around those variables to pass to GridSearchCV.\n",
    "param_grid.update({\n",
    "    'n_estimators': build_params(1, 2, 50, var='n_estimators'),\n",
    "    'min_samples_split': build_params(0, 3, 3, var='min_samples_split'),\n",
    "    'min_samples_leaf': build_params(0, 3, 3, var='min_samples_leaf'),\n",
    "    'max_features': [param_grid['max_features']],\n",
    "    'max_depth': build_params(1, 2, 10, var='max_depth'),\n",
    "    'bootstrap': [param_grid['bootstrap']]\n",
    "})\n",
    "\n",
    "# param_grid['n_estimators'].extend([int(param_grid['n_estimators'][-1] * 1.5)]) # Add a relatively large value.\n",
    "# param_grid['max_depth'].append(None)\n",
    "param_grid"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-13T16:07:22.323843350Z",
     "start_time": "2023-08-13T16:07:22.318285501Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 81 candidates, totalling 243 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[0;32mIn [70]\u001B[0m, in \u001B[0;36m<cell line: 11>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      2\u001B[0m base_rf_regressor \u001B[38;5;241m=\u001B[39m RandomForestRegressor(criterion\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpoisson\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m      3\u001B[0m grid_search_rf \u001B[38;5;241m=\u001B[39m GridSearchCV(\n\u001B[1;32m      4\u001B[0m     base_rf_regressor,\n\u001B[1;32m      5\u001B[0m     param_grid,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m      9\u001B[0m     verbose\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m\n\u001B[1;32m     10\u001B[0m )\n\u001B[0;32m---> 11\u001B[0m \u001B[43mgrid_search_rf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train_trimmed\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     12\u001B[0m best_rf_model_tuned \u001B[38;5;241m=\u001B[39m grid_search_rf\u001B[38;5;241m.\u001B[39mbest_estimator_\n\u001B[1;32m     13\u001B[0m best_rf_model_tuned\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:891\u001B[0m, in \u001B[0;36mBaseSearchCV.fit\u001B[0;34m(self, X, y, groups, **fit_params)\u001B[0m\n\u001B[1;32m    885\u001B[0m     results \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_format_results(\n\u001B[1;32m    886\u001B[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001B[1;32m    887\u001B[0m     )\n\u001B[1;32m    889\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m results\n\u001B[0;32m--> 891\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run_search\u001B[49m\u001B[43m(\u001B[49m\u001B[43mevaluate_candidates\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    893\u001B[0m \u001B[38;5;66;03m# multimetric is determined here because in the case of a callable\u001B[39;00m\n\u001B[1;32m    894\u001B[0m \u001B[38;5;66;03m# self.scoring the return type is only known after calling\u001B[39;00m\n\u001B[1;32m    895\u001B[0m first_test_score \u001B[38;5;241m=\u001B[39m all_out[\u001B[38;5;241m0\u001B[39m][\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtest_scores\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:1392\u001B[0m, in \u001B[0;36mGridSearchCV._run_search\u001B[0;34m(self, evaluate_candidates)\u001B[0m\n\u001B[1;32m   1390\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_run_search\u001B[39m(\u001B[38;5;28mself\u001B[39m, evaluate_candidates):\n\u001B[1;32m   1391\u001B[0m     \u001B[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001B[39;00m\n\u001B[0;32m-> 1392\u001B[0m     \u001B[43mevaluate_candidates\u001B[49m\u001B[43m(\u001B[49m\u001B[43mParameterGrid\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mparam_grid\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:838\u001B[0m, in \u001B[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001B[0;34m(candidate_params, cv, more_results)\u001B[0m\n\u001B[1;32m    830\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mverbose \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m    831\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\n\u001B[1;32m    832\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFitting \u001B[39m\u001B[38;5;132;01m{0}\u001B[39;00m\u001B[38;5;124m folds for each of \u001B[39m\u001B[38;5;132;01m{1}\u001B[39;00m\u001B[38;5;124m candidates,\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    833\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m totalling \u001B[39m\u001B[38;5;132;01m{2}\u001B[39;00m\u001B[38;5;124m fits\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\n\u001B[1;32m    834\u001B[0m             n_splits, n_candidates, n_candidates \u001B[38;5;241m*\u001B[39m n_splits\n\u001B[1;32m    835\u001B[0m         )\n\u001B[1;32m    836\u001B[0m     )\n\u001B[0;32m--> 838\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[43mparallel\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    839\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdelayed\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_fit_and_score\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    840\u001B[0m \u001B[43m        \u001B[49m\u001B[43mclone\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbase_estimator\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    841\u001B[0m \u001B[43m        \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    842\u001B[0m \u001B[43m        \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    843\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtrain\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    844\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtest\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtest\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    845\u001B[0m \u001B[43m        \u001B[49m\u001B[43mparameters\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mparameters\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    846\u001B[0m \u001B[43m        \u001B[49m\u001B[43msplit_progress\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43msplit_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_splits\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    847\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcandidate_progress\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcand_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_candidates\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    848\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mfit_and_score_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    849\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    850\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mcand_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparameters\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43msplit_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mproduct\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    851\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43menumerate\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcandidate_params\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43menumerate\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcv\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msplit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgroups\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    852\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    853\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    855\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(out) \u001B[38;5;241m<\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m    856\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    857\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNo fits were performed. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    858\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWas the CV iterator empty? \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    859\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWere there no candidates?\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    860\u001B[0m     )\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.9/site-packages/joblib/parallel.py:1056\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[0;34m(self, iterable)\u001B[0m\n\u001B[1;32m   1053\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_iterating \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[1;32m   1055\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backend\u001B[38;5;241m.\u001B[39mretrieval_context():\n\u001B[0;32m-> 1056\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mretrieve\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1057\u001B[0m \u001B[38;5;66;03m# Make sure that we get a last message telling us we are done\u001B[39;00m\n\u001B[1;32m   1058\u001B[0m elapsed_time \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime() \u001B[38;5;241m-\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_start_time\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.9/site-packages/joblib/parallel.py:935\u001B[0m, in \u001B[0;36mParallel.retrieve\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    933\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    934\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backend, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124msupports_timeout\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;28;01mFalse\u001B[39;00m):\n\u001B[0;32m--> 935\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_output\u001B[38;5;241m.\u001B[39mextend(\u001B[43mjob\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[1;32m    936\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    937\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_output\u001B[38;5;241m.\u001B[39mextend(job\u001B[38;5;241m.\u001B[39mget())\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py:542\u001B[0m, in \u001B[0;36mLokyBackend.wrap_future_result\u001B[0;34m(future, timeout)\u001B[0m\n\u001B[1;32m    539\u001B[0m \u001B[38;5;124;03m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001B[39;00m\n\u001B[1;32m    540\u001B[0m \u001B[38;5;124;03mAsyncResults.get from multiprocessing.\"\"\"\u001B[39;00m\n\u001B[1;32m    541\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 542\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfuture\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mresult\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    543\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m CfTimeoutError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    544\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTimeoutError\u001B[39;00m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01me\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.9/concurrent/futures/_base.py:441\u001B[0m, in \u001B[0;36mFuture.result\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    438\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_state \u001B[38;5;241m==\u001B[39m FINISHED:\n\u001B[1;32m    439\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m__get_result()\n\u001B[0;32m--> 441\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_condition\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwait\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    443\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_state \u001B[38;5;129;01min\u001B[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001B[1;32m    444\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m CancelledError()\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.9/threading.py:312\u001B[0m, in \u001B[0;36mCondition.wait\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    310\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:    \u001B[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001B[39;00m\n\u001B[1;32m    311\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m timeout \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 312\u001B[0m         \u001B[43mwaiter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43macquire\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    313\u001B[0m         gotit \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m    314\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# 81 fits @ n_estimators=400 = 8m.\n",
    "base_rf_regressor = RandomForestRegressor(criterion='poisson')\n",
    "grid_search_rf = GridSearchCV(\n",
    "    base_rf_regressor,\n",
    "    param_grid,\n",
    "    scoring=make_scorer(weighted_mae_fun, greater_is_better=False),\n",
    "    cv=3,\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "grid_search_rf.fit(X_train_trimmed, y_train)\n",
    "best_rf_model_tuned = grid_search_rf.best_estimator_\n",
    "best_rf_model_tuned"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-13T15:58:56.102784700Z",
     "start_time": "2023-08-13T15:58:53.280895759Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted Mean Absolute Error: 1.12.\n"
     ]
    }
   ],
   "source": [
    "gridsearch_accuracy = evaluate_wmae(best_rf_model_tuned, X_val_trimmed, y_val)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-13T14:39:22.678870220Z",
     "start_time": "2023-08-13T14:39:19.224610625Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "#### GB\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# param_grid_gb = {\n",
    "#     'n_estimators': [100, 200, 300],\n",
    "#     'learning_rate': [0.01, 0.1, 0.2],\n",
    "#     'max_depth': [3, 4, 5]\n",
    "# }"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# base_gbr_regressor = GradientBoostingRegressor()\n",
    "# grid_search_gb = GridSearchCV(\n",
    "#     base_gbr_regressor,\n",
    "#     param_grid_gb,\n",
    "#     scoring=make_scorer(weighted_mae_fun),\n",
    "#     cv=3,\n",
    "#     n_jobs=-1\n",
    "# )\n",
    "# grid_search_gb.fit(X_train_trimmed, y_train)\n",
    "# best_gb_model_tuned = grid_search_gb.best_estimator_\n",
    "# best_gb_model_tuned"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "#### Results\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [],
   "source": [
    "predictions_rf_tuned = best_rf_model_tuned.predict(X_val_trimmed)\n",
    "# predictions_gb_tuned = best_gb_model_tuned.predict(X_val_trimmed)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-12T22:59:45.018490963Z",
     "start_time": "2023-08-12T22:59:44.824493248Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [45722, 45723]",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Input \u001B[0;32mIn [55]\u001B[0m, in \u001B[0;36m<cell line: 2>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# RF\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m mse_rf_tuned \u001B[38;5;241m=\u001B[39m \u001B[43mmean_squared_error\u001B[49m\u001B[43m(\u001B[49m\u001B[43my_val\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpredictions_rf_tuned\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      3\u001B[0m rmse_rf_tuned \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39msqrt(mse_rf_tuned)\n\u001B[1;32m      4\u001B[0m mae_rf_tuned \u001B[38;5;241m=\u001B[39m mean_absolute_error(y_val, predictions_rf_tuned)\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py:438\u001B[0m, in \u001B[0;36mmean_squared_error\u001B[0;34m(y_true, y_pred, sample_weight, multioutput, squared)\u001B[0m\n\u001B[1;32m    378\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mmean_squared_error\u001B[39m(\n\u001B[1;32m    379\u001B[0m     y_true, y_pred, \u001B[38;5;241m*\u001B[39m, sample_weight\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, multioutput\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124muniform_average\u001B[39m\u001B[38;5;124m\"\u001B[39m, squared\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m    380\u001B[0m ):\n\u001B[1;32m    381\u001B[0m     \u001B[38;5;124;03m\"\"\"Mean squared error regression loss.\u001B[39;00m\n\u001B[1;32m    382\u001B[0m \n\u001B[1;32m    383\u001B[0m \u001B[38;5;124;03m    Read more in the :ref:`User Guide <mean_squared_error>`.\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    436\u001B[0m \u001B[38;5;124;03m    0.825...\u001B[39;00m\n\u001B[1;32m    437\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 438\u001B[0m     y_type, y_true, y_pred, multioutput \u001B[38;5;241m=\u001B[39m \u001B[43m_check_reg_targets\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    439\u001B[0m \u001B[43m        \u001B[49m\u001B[43my_true\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_pred\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmultioutput\u001B[49m\n\u001B[1;32m    440\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    441\u001B[0m     check_consistent_length(y_true, y_pred, sample_weight)\n\u001B[1;32m    442\u001B[0m     output_errors \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39maverage((y_true \u001B[38;5;241m-\u001B[39m y_pred) \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m \u001B[38;5;241m2\u001B[39m, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m, weights\u001B[38;5;241m=\u001B[39msample_weight)\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py:94\u001B[0m, in \u001B[0;36m_check_reg_targets\u001B[0;34m(y_true, y_pred, multioutput, dtype)\u001B[0m\n\u001B[1;32m     60\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_check_reg_targets\u001B[39m(y_true, y_pred, multioutput, dtype\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnumeric\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[1;32m     61\u001B[0m     \u001B[38;5;124;03m\"\"\"Check that y_true and y_pred belong to the same regression task.\u001B[39;00m\n\u001B[1;32m     62\u001B[0m \n\u001B[1;32m     63\u001B[0m \u001B[38;5;124;03m    Parameters\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     92\u001B[0m \u001B[38;5;124;03m        the dtype argument passed to check_array.\u001B[39;00m\n\u001B[1;32m     93\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m---> 94\u001B[0m     \u001B[43mcheck_consistent_length\u001B[49m\u001B[43m(\u001B[49m\u001B[43my_true\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_pred\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     95\u001B[0m     y_true \u001B[38;5;241m=\u001B[39m check_array(y_true, ensure_2d\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m, dtype\u001B[38;5;241m=\u001B[39mdtype)\n\u001B[1;32m     96\u001B[0m     y_pred \u001B[38;5;241m=\u001B[39m check_array(y_pred, ensure_2d\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m, dtype\u001B[38;5;241m=\u001B[39mdtype)\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:332\u001B[0m, in \u001B[0;36mcheck_consistent_length\u001B[0;34m(*arrays)\u001B[0m\n\u001B[1;32m    330\u001B[0m uniques \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39munique(lengths)\n\u001B[1;32m    331\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(uniques) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m--> 332\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    333\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFound input variables with inconsistent numbers of samples: \u001B[39m\u001B[38;5;132;01m%r\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    334\u001B[0m         \u001B[38;5;241m%\u001B[39m [\u001B[38;5;28mint\u001B[39m(l) \u001B[38;5;28;01mfor\u001B[39;00m l \u001B[38;5;129;01min\u001B[39;00m lengths]\n\u001B[1;32m    335\u001B[0m     )\n",
      "\u001B[0;31mValueError\u001B[0m: Found input variables with inconsistent numbers of samples: [45722, 45723]"
     ]
    }
   ],
   "source": [
    "# RF\n",
    "mse_rf_tuned = mean_squared_error(y_val, predictions_rf_tuned)\n",
    "rmse_rf_tuned = np.sqrt(mse_rf_tuned)\n",
    "mae_rf_tuned = mean_absolute_error(y_val, predictions_rf_tuned)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-12T22:59:46.735469711Z",
     "start_time": "2023-08-12T22:59:46.563094648Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# GB\n",
    "# mse_gb_tuned = mean_squared_error(y_val, predictions_gb_tuned)\n",
    "# rmse_gb_tuned = np.sqrt(mse_gb_tuned)\n",
    "# mae_gb_tuned = mean_absolute_error(y_val, predictions_gb_tuned)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"Random Forest Regression (Tuned) on Trimmed Dataset:\")\n",
    "print(f\"RMSE: {rmse_rf_tuned}\")\n",
    "print(f\"MAE: {mae_rf_tuned}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# print(\"\\nGradient Boosting Regression (Tuned) on Trimmed Dataset:\")\n",
    "# print(f\"RMSE: {rmse_gb_tuned}\")\n",
    "# print(f\"MAE: {mae_gb_tuned}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
